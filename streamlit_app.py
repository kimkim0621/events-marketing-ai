import streamlit as st
import sqlite3
import pandas as pd
import numpy as np
import json
import os
import tempfile
import concurrent.futures
from datetime import datetime, timedelta
from pathlib import Path
import asyncio
import io
from typing import List
import plotly.express as px
import plotly.graph_objects as go

# å…±æœ‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š
try:
    from database_setup import SharedDatabase, setup_shared_database
    SHARED_DB_AVAILABLE = True
    if 'db_mode' not in st.session_state:
        st.session_state.db_mode = "shared"  # shared ã¾ãŸã¯ local
except ImportError:
    SHARED_DB_AVAILABLE = False
    if 'db_mode' not in st.session_state:
        st.session_state.db_mode = "local"

# ã‚¯ãƒ©ã‚¦ãƒ‰å¯¾å¿œã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹è¨­å®š
if "STREAMLIT_CLOUD" in os.environ or not os.path.exists("data"):
    # Streamlit Cloudç’°å¢ƒã¾ãŸã¯dataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆ
    DB_PATH = "events_marketing.db"
    # å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆï¼ˆã‚¨ãƒ©ãƒ¼å‡¦ç†ä»˜ãï¼‰
    try:
        os.makedirs("backups", exist_ok=True)
    except Exception:
        pass  # Streamlit Cloudã§ã¯æ›¸ãè¾¼ã¿æ¨©é™ãŒãªã„å ´åˆãŒã‚ã‚‹
else:
    # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ
    DB_PATH = "data/events_marketing.db"
    try:
        os.makedirs("data/backups", exist_ok=True)
    except Exception:
        pass

# ç¤¾å†…ãƒ‡ãƒ¼ã‚¿ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from internal_data_system import InternalDataSystem
    from data_cleaner import DataCleaner
    INTERNAL_DATA_AVAILABLE = True
except ImportError as e:
    # Streamlit Cloudã§ã¯è­¦å‘Šã®ã¿è¡¨ç¤º
    if "STREAMLIT_CLOUD" in os.environ:
        st.warning("âš ï¸ ç¤¾å†…ãƒ‡ãƒ¼ã‚¿ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒï¼‰")
    else:
        st.error(f"âš ï¸ ç¤¾å†…ãƒ‡ãƒ¼ã‚¿ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“: {str(e)}")
    INTERNAL_DATA_AVAILABLE = False



# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ã‚¤ãƒ™ãƒ³ãƒˆé›†å®¢æ–½ç­–ææ¡ˆAI",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .sub-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #2c3e50;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .metric-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
        margin-bottom: 1rem;
    }
    .campaign-card {
        background-color: #ffffff;
        padding: 1.5rem;
        border-radius: 0.5rem;
        border: 1px solid #e9ecef;
        margin-bottom: 1rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .free-campaign {
        border-left: 4px solid #28a745;
    }
    .paid-campaign {
        border-left: 4px solid #ffc107;
    }
    
    /* Multiselectã®ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã‚’ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ã«ã™ã‚‹ */
    .stMultiSelect > div[data-baseweb="select"] > div {
        max-height: 300px;
        overflow-y: auto;
    }
    
    /* ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã®ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«è¨­å®š */
    div[data-baseweb="popover"] {
        max-height: 400px;
    }
    
    div[data-baseweb="popover"] > div {
        max-height: 350px;
        overflow-y: auto;
    }
    
    /* ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒãƒ¼ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
    div[data-baseweb="popover"] > div::-webkit-scrollbar {
        width: 8px;
    }
    
    div[data-baseweb="popover"] > div::-webkit-scrollbar-track {
        background: #f1f1f1;
        border-radius: 4px;
    }
    
    div[data-baseweb="popover"] > div::-webkit-scrollbar-thumb {
        background: #c1c1c1;
        border-radius: 4px;
    }
    
    div[data-baseweb="popover"] > div::-webkit-scrollbar-thumb:hover {
        background: #a8a8a8;
    }
</style>
""", unsafe_allow_html=True)

def main():
    # ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆUIã‚’å‘¼ã³å‡ºã—
    try:
        from data_import_ui import main as data_import_main
        data_import_main()
    except ImportError:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒã®UI
        initialize_database()
        
        st.markdown('<h1 class="main-header">ğŸ¯ ã‚¤ãƒ™ãƒ³ãƒˆé›†å®¢æ–½ç­–ææ¡ˆAI</h1>', unsafe_allow_html=True)
        
        # ã‚¿ãƒ–ã®è¿½åŠ 
        main_tab, data_tab = st.tabs(["ğŸ¯ æ–½ç­–ææ¡ˆ", "ğŸ“Š ãƒ‡ãƒ¼ã‚¿ç®¡ç†"])
        
        with data_tab:
            show_data_management()
        
        with main_tab:
            show_main_interface()

def initialize_database():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®åˆæœŸåŒ–ï¼ˆã‚µã‚¤ãƒ¬ãƒ³ãƒˆå‡¦ç†ï¼‰"""
    if SHARED_DB_AVAILABLE:
        # Supabaseãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–
        try:
            if 'shared_db' not in st.session_state:
                db = setup_shared_database()
                if db:
                    st.session_state['shared_db'] = db
        except Exception:
            pass  # ã‚¨ãƒ©ãƒ¼ã¯è¨˜éŒ²ã™ã‚‹ãŒè¡¨ç¤ºã—ãªã„
    else:
        # ãƒ­ãƒ¼ã‚«ãƒ«SQLiteã®åˆæœŸåŒ–
        try:
            if not os.path.exists(DB_PATH):
                # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
                os.makedirs(os.path.dirname(DB_PATH) if os.path.dirname(DB_PATH) else ".", exist_ok=True)
        except Exception:
            pass  # ã‚¨ãƒ©ãƒ¼ã¯è¨˜éŒ²ã™ã‚‹ãŒè¡¨ç¤ºã—ãªã„

def show_main_interface():
    """ãƒ¡ã‚¤ãƒ³æ–½ç­–ææ¡ˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã®å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
    with st.sidebar:
        st.markdown("## ğŸ“ ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±å…¥åŠ›")
        
        # åŸºæœ¬æƒ…å ±
        event_name = st.text_input("ã‚¤ãƒ™ãƒ³ãƒˆå", placeholder="ä¾‹: AIæŠ€è¡“ã‚»ãƒŸãƒŠãƒ¼")
        
        event_category = st.selectbox(
            "ã‚¤ãƒ™ãƒ³ãƒˆã‚«ãƒ†ã‚´ãƒª",
            ["conference", "seminar", "workshop", "webinar", "networking", "product_launch"],
            format_func=lambda x: {
                "conference": "ã‚«ãƒ³ãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹",
                "seminar": "ã‚»ãƒŸãƒŠãƒ¼", 
                "workshop": "ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—",
                "webinar": "ã‚¦ã‚§ãƒ“ãƒŠãƒ¼",
                "networking": "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚­ãƒ³ã‚°",
                "product_launch": "è£½å“ç™ºè¡¨"
            }[x]
        )
        
        event_theme = st.text_area("ã‚¤ãƒ™ãƒ³ãƒˆãƒ†ãƒ¼ãƒãƒ»å†…å®¹", placeholder="ä¾‹: æœ€æ–°ã®AIæŠ€è¡“å‹•å‘ã¨å®Ÿè·µäº‹ä¾‹")
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨­å®š
        st.markdown("### ğŸ¯ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨­å®š")
        
        with st.expander("ğŸ¢ æ¥­ç¨®é¸æŠ (34æ¥­ç¨®)", expanded=True):
            # æ¥­ç¨®ã®é¸æŠè‚¢ï¼ˆã€Œã™ã¹ã¦ã€ã‚’æœ€ä¸Šæ®µã«è¿½åŠ ï¼‰
            industry_options = ["ã™ã¹ã¦", "è¼¸é€ç”¨æ©Ÿå™¨", "é›»æ°—æ©Ÿå™¨", "å°å£²æ¥­", "å¸å£²æ¥­", "åŒ»è–¬å“", "ãã®ä»–è£½å“", "ç²¾å¯†æ©Ÿå™¨", "ä¸å‹•ç”£æ¥­", "é™¸é‹æ¥­", "é‰„é‹¼", "é‰±æ¥­", "çŸ³æ²¹ãƒ»çŸ³ç‚­è£½å“", "éé‰„é‡‘å±", "ç©ºé‹æ¥­", "ã‚¬ãƒ©ã‚¹ãƒ»åœŸçŸ³è£½å“", "ãƒ‘ãƒ«ãƒ—ãƒ»ç´™", "æ°´ç”£ãƒ»è¾²æ—æ¥­", "éŠ€è¡Œæ¥­", "ã‚µãƒ¼ãƒ“ã‚¹æ¥­", "æƒ…å ±ãƒ»é€šä¿¡æ¥­", "åŒ–å­¦", "ä¿é™ºæ¥­", "é£Ÿæ–™å“", "æ©Ÿæ¢°", "ã‚´ãƒ è£½å“", "å»ºè¨­æ¥­", "è¨¼åˆ¸ã€å•†å“å…ˆç‰©å–å¼•æ¥­", "é›»æ°—ãƒ»ã‚¬ã‚¹æ¥­", "æµ·é‹æ¥­", "ãã®ä»–é‡‘èæ¥­", "ç¹Šç¶­è£½å“", "é‡‘å±è£½å“", "å€‰åº«ãƒ»é‹è¼¸é–¢é€£æ¥­", "ãã®ä»–"]
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
            if 'selected_industries' not in st.session_state:
                st.session_state.selected_industries = ["æƒ…å ±ãƒ»é€šä¿¡æ¥­"]
            
            # ã€Œã™ã¹ã¦ã€é¸æŠã®å‡¦ç†
            def on_industries_change():
                selected = st.session_state.industries_multiselect
                if "ã™ã¹ã¦" in selected and "ã™ã¹ã¦" not in st.session_state.selected_industries:
                    # ã€Œã™ã¹ã¦ã€ãŒæ–°ã—ãé¸æŠã•ã‚ŒãŸå ´åˆ
                    st.session_state.selected_industries = industry_options.copy()
                elif "ã™ã¹ã¦" not in selected and "ã™ã¹ã¦" in st.session_state.selected_industries:
                    # ã€Œã™ã¹ã¦ã€ãŒè§£é™¤ã•ã‚ŒãŸå ´åˆ
                    st.session_state.selected_industries = []
                elif "ã™ã¹ã¦" in selected:
                    # ã€Œã™ã¹ã¦ã€ãŒé¸æŠã•ã‚Œã¦ã„ã‚‹çŠ¶æ…‹ã§ä»–ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆ
                    if len(selected) < len(industry_options):
                        # ä¸€éƒ¨è§£é™¤ã•ã‚ŒãŸå ´åˆã€ã€Œã™ã¹ã¦ã€ã‚’é™¤å¤–
                        st.session_state.selected_industries = [opt for opt in selected if opt != "ã™ã¹ã¦"]
                else:
                    # é€šå¸¸ã®é¸æŠ
                    st.session_state.selected_industries = selected
                    # å…¨ã¦é¸æŠã•ã‚Œã¦ã„ã‚‹å ´åˆã€ã€Œã™ã¹ã¦ã€ã‚’è¿½åŠ 
                    if len(selected) == len(industry_options) - 1:
                        st.session_state.selected_industries = ["ã™ã¹ã¦"] + selected
            
            industries = st.multiselect(
                "æ¥­ç¨®",
                industry_options,
                default=st.session_state.selected_industries,
                key="industries_multiselect",
                on_change=on_industries_change,
                help="è¤‡æ•°é¸æŠå¯èƒ½ã§ã™ã€‚ã€Œã™ã¹ã¦ã€ã‚’é¸æŠã™ã‚‹ã¨å…¨æ¥­ç¨®ãŒå¯¾è±¡ã«ãªã‚Šã¾ã™ã€‚"
            )
            
            # è¡¨ç¤ºç”¨ã«å®Ÿéš›ã®æ¥­ç¨®ã®ã¿ã‚’æŠ½å‡º
            industries_actual = [ind for ind in industries if ind != "ã™ã¹ã¦"] if "ã™ã¹ã¦" not in industries else [ind for ind in industry_options if ind != "ã™ã¹ã¦"]
        
        with st.expander("ğŸ‘¥ è·ç¨®é¸æŠ (31è·ç¨®)", expanded=True):
            # è·ç¨®ã®é¸æŠè‚¢ï¼ˆã€Œã™ã¹ã¦ã€ã‚’æœ€ä¸Šæ®µã«è¿½åŠ ï¼‰
            job_title_options = ["ã™ã¹ã¦", "CTO", "VPoE", "EM", "ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "ã‚¤ãƒ³ãƒ•ãƒ©ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "ãƒ•ãƒ«ã‚¹ã‚¿ãƒƒã‚¯ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "ãƒ¢ãƒã‚¤ãƒ«ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ»ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆ", "ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆ", "æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ ", "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "UXã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "ãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼", "å­¦ç”Ÿ", "ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªã‚¹ãƒˆ", "CPO", "VPoT/VPoP", "ãƒ†ãƒƒã‚¯ãƒªãƒ¼ãƒ‰", "ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "SRE", "ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼", "DevOpsã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "QAã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "æ©Ÿæ¢°å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼", "SIer", "ã‚²ãƒ¼ãƒ é–‹ç™ºã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "çµ„ã¿è¾¼ã¿ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ä»¥å¤–", "ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢"]
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
            if 'selected_job_titles' not in st.session_state:
                st.session_state.selected_job_titles = ["ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢"]
            
            # ã€Œã™ã¹ã¦ã€é¸æŠã®å‡¦ç†
            def on_job_titles_change():
                selected = st.session_state.job_titles_multiselect
                if "ã™ã¹ã¦" in selected and "ã™ã¹ã¦" not in st.session_state.selected_job_titles:
                    st.session_state.selected_job_titles = job_title_options.copy()
                elif "ã™ã¹ã¦" not in selected and "ã™ã¹ã¦" in st.session_state.selected_job_titles:
                    st.session_state.selected_job_titles = []
                elif "ã™ã¹ã¦" in selected:
                    if len(selected) < len(job_title_options):
                        st.session_state.selected_job_titles = [opt for opt in selected if opt != "ã™ã¹ã¦"]
                else:
                    st.session_state.selected_job_titles = selected
                    if len(selected) == len(job_title_options) - 1:
                        st.session_state.selected_job_titles = ["ã™ã¹ã¦"] + selected
            
            job_titles = st.multiselect(
                "è·ç¨®",
                job_title_options,
                default=st.session_state.selected_job_titles,
                key="job_titles_multiselect",
                on_change=on_job_titles_change,
                help="è¤‡æ•°é¸æŠå¯èƒ½ã§ã™ã€‚ã€Œã™ã¹ã¦ã€ã‚’é¸æŠã™ã‚‹ã¨å…¨è·ç¨®ãŒå¯¾è±¡ã«ãªã‚Šã¾ã™ã€‚"
            )
            
            # è¡¨ç¤ºç”¨ã«å®Ÿéš›ã®è·ç¨®ã®ã¿ã‚’æŠ½å‡º
            job_titles_actual = [jt for jt in job_titles if jt != "ã™ã¹ã¦"] if "ã™ã¹ã¦" not in job_titles else [jt for jt in job_title_options if jt != "ã™ã¹ã¦"]
        
        with st.expander("ğŸ“Š å¾“æ¥­å“¡è¦æ¨¡é¸æŠ (8æ®µéš)", expanded=False):
            # å¾“æ¥­å“¡è¦æ¨¡ã®é¸æŠè‚¢ï¼ˆã€Œã™ã¹ã¦ã€ã‚’æœ€ä¸Šæ®µã«è¿½åŠ ï¼‰
            company_size_options = ["ã™ã¹ã¦", "10åä»¥ä¸‹", "11åï½50å", "51åï½100å", "101åï½300å", "301åï½500å", "501åï½1,000å", "1,001ï½5,000å", "5,001åä»¥ä¸Š"]
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
            if 'selected_company_sizes' not in st.session_state:
                st.session_state.selected_company_sizes = ["101åï½300å", "301åï½500å"]
            
            # ã€Œã™ã¹ã¦ã€é¸æŠã®å‡¦ç†
            def on_company_sizes_change():
                selected = st.session_state.company_sizes_multiselect
                if "ã™ã¹ã¦" in selected and "ã™ã¹ã¦" not in st.session_state.selected_company_sizes:
                    st.session_state.selected_company_sizes = company_size_options.copy()
                elif "ã™ã¹ã¦" not in selected and "ã™ã¹ã¦" in st.session_state.selected_company_sizes:
                    st.session_state.selected_company_sizes = []
                elif "ã™ã¹ã¦" in selected:
                    if len(selected) < len(company_size_options):
                        st.session_state.selected_company_sizes = [opt for opt in selected if opt != "ã™ã¹ã¦"]
                else:
                    st.session_state.selected_company_sizes = selected
                    if len(selected) == len(company_size_options) - 1:
                        st.session_state.selected_company_sizes = ["ã™ã¹ã¦"] + selected
            
            company_sizes = st.multiselect(
                "å¾“æ¥­å“¡è¦æ¨¡",
                company_size_options,
                default=st.session_state.selected_company_sizes,
                key="company_sizes_multiselect",
                on_change=on_company_sizes_change,
                help="è¤‡æ•°é¸æŠå¯èƒ½ã§ã™ã€‚ã€Œã™ã¹ã¦ã€ã‚’é¸æŠã™ã‚‹ã¨å…¨è¦æ¨¡ãŒå¯¾è±¡ã«ãªã‚Šã¾ã™ã€‚"
            )
            
            # è¡¨ç¤ºç”¨ã«å®Ÿéš›ã®å¾“æ¥­å“¡è¦æ¨¡ã®ã¿ã‚’æŠ½å‡º
            company_sizes_actual = [cs for cs in company_sizes if cs != "ã™ã¹ã¦"] if "ã™ã¹ã¦" not in company_sizes else [cs for cs in company_size_options if cs != "ã™ã¹ã¦"]
        
        # ç›®æ¨™ãƒ»äºˆç®—è¨­å®š
        st.markdown("### ğŸ’° ç›®æ¨™ãƒ»äºˆç®—è¨­å®š")
        
        target_attendees = st.number_input("ç›®æ¨™ç”³è¾¼äººæ•°", min_value=1, value=100)
        budget = st.number_input("é›†å®¢äºˆç®—ï¼ˆå††ï¼‰", min_value=0, value=500000, step=50000)
        
        event_date = st.date_input(
            "é–‹å‚¬æ—¥",
            value=datetime.now().date() + timedelta(days=30),
            min_value=datetime.now().date()
        )
        
        is_free_event = st.checkbox("ç„¡æ–™ã‚¤ãƒ™ãƒ³ãƒˆ", value=True)
        
        event_format = st.selectbox(
            "é–‹å‚¬å½¢å¼",
            ["online", "offline", "hybrid"],
            format_func=lambda x: {"online": "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³", "offline": "ã‚ªãƒ•ãƒ©ã‚¤ãƒ³", "hybrid": "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰"}[x]
        )
        
        # AIäºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³é¸æŠ
        use_ai_engine = st.checkbox("ğŸ§  é«˜åº¦AIäºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½¿ç”¨", value=False, help="æ©Ÿæ¢°å­¦ç¿’ãƒ™ãƒ¼ã‚¹ã®é«˜åº¦ãªäºˆæ¸¬ã‚’è¡Œã„ã¾ã™ï¼ˆãƒ™ãƒ¼ã‚¿ç‰ˆï¼‰")
        
        # ææ¡ˆç”Ÿæˆãƒœã‚¿ãƒ³
        if st.button("ğŸš€ æ–½ç­–ææ¡ˆã‚’ç”Ÿæˆ", type="primary", use_container_width=True):
            if event_name and event_theme and industries_actual and job_titles_actual:
                generate_recommendations(
                    event_name, event_category, event_theme, industries_actual, job_titles_actual,
                    company_sizes_actual, target_attendees, budget, event_date, is_free_event, event_format, use_ai_engine
                )
            else:
                st.error("å¿…é ˆé …ç›®ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã®å¤–å´ã«ç§»å‹•ï¼‰
    if 'recommendations' not in st.session_state:
        show_welcome_screen()
    else:
        show_recommendations()

def show_data_management():
    """ãƒ‡ãƒ¼ã‚¿ç®¡ç†ç”»é¢"""
    st.markdown("## ğŸ“Š ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šçŠ¶æ³ã‚’è¡¨ç¤º
    if SHARED_DB_AVAILABLE and 'shared_db' in st.session_state:
        st.info("ğŸŒ Supabaseå…±æœ‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨ä¸­")
        # Supabaseã§ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚’å®Ÿè£…
        show_supabase_data_management()
        return
    elif INTERNAL_DATA_AVAILABLE:
        st.info("ğŸ’» ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ä¸­")
        # åˆæœŸåŒ–
        if 'data_system' not in st.session_state:
            st.session_state['data_system'] = InternalDataSystem()
        data_system = st.session_state['data_system']
    else:
        st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆåŸºæœ¬æ©Ÿèƒ½ã®ã¿åˆ©ç”¨å¯èƒ½ï¼‰")
        show_basic_data_management()
        return
    
    # ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ã®è¡¨ç¤º
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### ğŸ“ˆ ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿æ¦‚è¦")
        
        # ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆã®è¡¨ç¤º
        try:
            # ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ã‚’å–å¾—ã—ã¦è¡¨ç¤º
            import sqlite3
            conn = sqlite3.connect(data_system.db_path)
            cursor = conn.cursor()
            
            # åŸºæœ¬çµ±è¨ˆ
            tables_stats = {}
            tables = ['historical_events', 'media_performance', 'media_detailed_attributes', 'internal_knowledge']
            
            for table in tables:
                try:
                    cursor.execute(f"SELECT COUNT(*) FROM {table}")
                    count = cursor.fetchone()[0]
                    tables_stats[table] = count
                except:
                    tables_stats[table] = 0
            
            # çµ±è¨ˆè¡¨ç¤º
            col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
            
            with col_stat1:
                st.metric("ğŸ“… ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿", f"{tables_stats['historical_events']}ä»¶")
            
            with col_stat2:
                st.metric("ğŸ“º ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ‡ãƒ¼ã‚¿", f"{tables_stats['media_performance']}ä»¶")
            
            with col_stat3:
                st.metric("ğŸ¯ ãƒ¡ãƒ‡ã‚£ã‚¢å±æ€§", f"{tables_stats['media_detailed_attributes']}ä»¶")
            
            with col_stat4:
                st.metric("ğŸ§  ç¤¾å†…çŸ¥è¦‹", f"{tables_stats['internal_knowledge']}ä»¶")
            
            conn.close()
            
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆã®å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    with col2:
        st.markdown("### âš¡ ã‚¯ã‚¤ãƒƒã‚¯ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
        
        if st.button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆæ›´æ–°", use_container_width=True):
            st.rerun()
        
        if st.button("ğŸ“‹ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ", use_container_width=True):
            show_detailed_data_report(data_system)
    
    st.markdown("---")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ©Ÿèƒ½
    import_tab, knowledge_tab, clean_tab, analysis_tab = st.tabs(["ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆ", "ğŸ§  çŸ¥è¦‹ç®¡ç†", "ğŸ§¹ ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°", "ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æ"])
    
    with import_tab:
        show_data_import_interface(data_system)
    
    with knowledge_tab:
        show_knowledge_management(data_system)
    
    with clean_tab:
        show_data_cleaning_interface()
    
    with analysis_tab:
        show_data_analysis(data_system)

def analyze_multiple_pdfs(pdf_files: List, data_system, max_workers=4, show_detailed_results=True):
    """è¤‡æ•°PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸¦è¡Œè§£æå‡¦ç†"""
    
    # å…¨ä½“ã®é€²æ—è¡¨ç¤º
    progress_placeholder = st.empty()
    status_placeholder = st.empty()
    results_placeholder = st.empty()
    
    # çµæœæ ¼ç´ç”¨
    all_results = []
    successful_files = 0
    failed_files = 0
    total_media_extracted = 0
    total_insights_extracted = 0
    
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®åˆæœŸåŒ–
    progress_bar = progress_placeholder.progress(0)
    status_placeholder.info("ğŸ“„ è§£ææº–å‚™ä¸­...")
    
    def process_single_pdf(file_info):
        """å˜ä¸€PDFãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†"""
        file, index = file_info
        try:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
                tmp_file.write(file.getvalue())
                tmp_file_path = tmp_file.name
            
            # PDFè§£æå®Ÿè¡Œ
            result = data_system.extract_pdf_insights(tmp_file_path)
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            try:
                os.unlink(tmp_file_path)
            except:
                pass
            
            return {
                'file_name': file.name,
                'index': index,
                'success': result.get('success', False),
                'result': result,
                'file_size': len(file.getvalue()) / 1024  # KB
            }
            
        except Exception as e:
            return {
                'file_name': file.name,
                'index': index,
                'success': False,
                'error': str(e),
                'file_size': len(file.getvalue()) / 1024  # KB
            }
    
    # ä¸¦è¡Œå‡¦ç†ã§ã®è§£æå®Ÿè¡Œ
    with concurrent.futures.ThreadPoolExecutor(max_workers=min(max_workers, len(pdf_files))) as executor:
        # ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä»˜ä¸
        file_list = [(file, i) for i, file in enumerate(pdf_files)]
        
        # éåŒæœŸå®Ÿè¡Œ
        future_to_file = {executor.submit(process_single_pdf, file_info): file_info for file_info in file_list}
        
        # çµæœã®åé›†
        completed = 0
        for future in concurrent.futures.as_completed(future_to_file):
            completed += 1
            progress = completed / len(pdf_files)
            progress_bar.progress(progress)
            
            # ç¾åœ¨ã®çŠ¶æ³ã‚’æ›´æ–°
            status_placeholder.info(f"ğŸ“„ è§£æä¸­... ({completed}/{len(pdf_files)}) - {progress*100:.1f}%å®Œäº†")
            
            try:
                result = future.result()
                all_results.append(result)
                
                if result['success']:
                    successful_files += 1
                    if 'result' in result:
                        total_media_extracted += result['result'].get('media_extracted', 0)
                        total_insights_extracted += result['result'].get('insights_extracted', 0)
                else:
                    failed_files += 1
                    
            except Exception as e:
                failed_files += 1
                all_results.append({
                    'file_name': 'Unknown',
                    'success': False,
                    'error': str(e)
                })
    
    # çµæœè¡¨ç¤º
    progress_placeholder.empty()
    
    # å…¨ä½“ã‚µãƒãƒªãƒ¼
    if successful_files > 0:
        status_placeholder.success(f"âœ… è§£æå®Œäº†ï¼ æˆåŠŸ: {successful_files}ä»¶ / å¤±æ•—: {failed_files}ä»¶")
        
        # ã‚«ãƒ©ãƒ å…¥ã‚Œå­ã‚¨ãƒ©ãƒ¼å›é¿ã®ãŸã‚ã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ç¸¦ä¸¦ã³ã§è¡¨ç¤º
        st.metric("ğŸ“º ç·ãƒ¡ãƒ‡ã‚£ã‚¢æƒ…å ±", f"{total_media_extracted}ä»¶")
        st.metric("ğŸ§  ç·çŸ¥è¦‹æƒ…å ±", f"{total_insights_extracted}ä»¶")
        st.metric("ğŸ“Š è§£ææˆåŠŸç‡", f"{successful_files/len(pdf_files)*100:.1f}%")
    else:
        status_placeholder.error(f"âŒ å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    # è©³ç´°çµæœè¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if show_detailed_results:
        with results_placeholder.container():
            st.markdown("##### ğŸ“‹ è©³ç´°è§£æçµæœ")
            
            # æˆåŠŸã—ãŸãƒ•ã‚¡ã‚¤ãƒ«
            if successful_files > 0:
                with st.expander(f"âœ… æˆåŠŸã—ãŸãƒ•ã‚¡ã‚¤ãƒ« ({successful_files}ä»¶)", expanded=True):
                    for result in all_results:
                        if result['success']:
                            media_count = result['result'].get('media_extracted', 0)
                            insights_count = result['result'].get('insights_extracted', 0)
                            st.success(f"ğŸ“„ **{result['file_name']}** ({result['file_size']:.1f} KB)")
                            st.write(f"   ğŸ“º ãƒ¡ãƒ‡ã‚£ã‚¢æƒ…å ±: {media_count}ä»¶ | ğŸ§  çŸ¥è¦‹æƒ…å ±: {insights_count}ä»¶")
            
            # å¤±æ•—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«
            if failed_files > 0:
                with st.expander(f"âŒ å¤±æ•—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ« ({failed_files}ä»¶)", expanded=False):
                    for result in all_results:
                        if not result['success']:
                            st.error(f"ğŸ“„ **{result['file_name']}** ({result.get('file_size', 0):.1f} KB)")
                            if 'error' in result:
                                st.write(f"   ã‚¨ãƒ©ãƒ¼: {result['error']}")
                            elif 'result' in result and 'error' in result['result']:
                                st.write(f"   ã‚¨ãƒ©ãƒ¼: {result['result']['error']}")
    else:
        # ç°¡æ˜“ã‚µãƒãƒªãƒ¼ã®ã¿
        results_placeholder.info("ğŸ’¡ è©³ç´°çµæœã®è¡¨ç¤ºãŒã‚ªãƒ•ã«ãªã£ã¦ã„ã¾ã™ã€‚è¨­å®šã§æœ‰åŠ¹ã«ã§ãã¾ã™ã€‚")

def show_data_import_interface(data_system):
    """ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
    st.markdown("#### ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ»ç®¡ç†")
    
    # ã‚¿ãƒ–æ§‹æˆã§å„ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã‚’åˆ†é›¢
    tab1, tab2, tab3 = st.tabs([
        "ğŸ“Š ã‚¤ãƒ™ãƒ³ãƒˆé›†å®¢å®Ÿç¸¾", 
        "ğŸ“º åª’ä½“æƒ…å ±",
        "ğŸ“ˆ ã‚¤ãƒ³ãƒãƒ¼ãƒˆå±¥æ­´"
    ])
    
    with tab1:
        # ã‚¤ãƒ™ãƒ³ãƒˆé›†å®¢å®Ÿç¸¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        st.markdown("##### ğŸ“Š ã‚¤ãƒ™ãƒ³ãƒˆé›†å®¢å®Ÿç¸¾ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
        
        # a. å¯¾è±¡ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ï¼ˆæ‰‹å…¥åŠ›ï¼‰
        st.markdown("#### ğŸ“ a. å¯¾è±¡ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ï¼ˆæ‰‹å…¥åŠ›ï¼‰")
        
        col1, col2 = st.columns(2)
        with col1:
            event_name = st.text_input("ã‚¤ãƒ™ãƒ³ãƒˆå", key="event_name_input", 
                                     placeholder="ä¾‹ï¼šAIæŠ€è¡“ã‚»ãƒŸãƒŠãƒ¼ 2025")
            event_theme = st.text_input("ã‚¤ãƒ™ãƒ³ãƒˆãƒ†ãƒ¼ãƒãƒ»å†…å®¹", key="event_theme_input", 
                                      placeholder="ä¾‹ï¼šç”ŸæˆAIã®æœ€æ–°å‹•å‘ã¨å®Ÿè£…æ–¹æ³•")
        
        with col2:
            event_category = st.selectbox("ã‚¤ãƒ™ãƒ³ãƒˆã‚«ãƒ†ã‚´ãƒª", 
                                        ["conference", "seminar", "workshop", "webinar", "networking", "product_launch"],
                                        format_func=lambda x: {
                                            "conference": "ã‚«ãƒ³ãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹",
                                            "seminar": "ã‚»ãƒŸãƒŠãƒ¼", 
                                            "workshop": "ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—",
                                            "webinar": "ã‚¦ã‚§ãƒ“ãƒŠãƒ¼",
                                            "networking": "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚­ãƒ³ã‚°",
                                            "product_launch": "è£½å“ç™ºè¡¨"
                                        }[x],
                                        key="event_category_input")
            event_date = st.date_input("é–‹å‚¬æ—¥", key="event_date_input")
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé¸æŠï¼ˆè¤‡æ•°é¸æŠå¯èƒ½ï¼‰
        st.markdown("**ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨­å®š**")
        col_target1, col_target2, col_target3 = st.columns(3)
        
        with col_target1:
            # æ¥­ç¨®ã®é¸æŠè‚¢ï¼ˆå³å´ã‚µã‚¤ãƒ‰ãƒãƒ¼ã¨åŒã˜34æ¥­ç¨®ï¼‰
            industry_options_import = ["ã™ã¹ã¦", "è¼¸é€ç”¨æ©Ÿå™¨", "é›»æ°—æ©Ÿå™¨", "å°å£²æ¥­", "å¸å£²æ¥­", "åŒ»è–¬å“", "ãã®ä»–è£½å“", "ç²¾å¯†æ©Ÿå™¨", "ä¸å‹•ç”£æ¥­", "é™¸é‹æ¥­", "é‰„é‹¼", "é‰±æ¥­", "çŸ³æ²¹ãƒ»çŸ³ç‚­è£½å“", "éé‰„é‡‘å±", "ç©ºé‹æ¥­", "ã‚¬ãƒ©ã‚¹ãƒ»åœŸçŸ³è£½å“", "ãƒ‘ãƒ«ãƒ—ãƒ»ç´™", "æ°´ç”£ãƒ»è¾²æ—æ¥­", "éŠ€è¡Œæ¥­", "ã‚µãƒ¼ãƒ“ã‚¹æ¥­", "æƒ…å ±ãƒ»é€šä¿¡æ¥­", "åŒ–å­¦", "ä¿é™ºæ¥­", "é£Ÿæ–™å“", "æ©Ÿæ¢°", "ã‚´ãƒ è£½å“", "å»ºè¨­æ¥­", "è¨¼åˆ¸ã€å•†å“å…ˆç‰©å–å¼•æ¥­", "é›»æ°—ãƒ»ã‚¬ã‚¹æ¥­", "æµ·é‹æ¥­", "ãã®ä»–é‡‘èæ¥­", "ç¹Šç¶­è£½å“", "é‡‘å±è£½å“", "å€‰åº«ãƒ»é‹è¼¸é–¢é€£æ¥­", "ãã®ä»–"]
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
            if 'selected_industries_import' not in st.session_state:
                st.session_state.selected_industries_import = ["æƒ…å ±ãƒ»é€šä¿¡æ¥­"]
            
            # ã€Œã™ã¹ã¦ã€é¸æŠã®å‡¦ç†
            def on_industries_import_change():
                selected = st.session_state.target_industries_multi
                if "ã™ã¹ã¦" in selected and "ã™ã¹ã¦" not in st.session_state.selected_industries_import:
                    # ã€Œã™ã¹ã¦ã€ãŒæ–°ã—ãé¸æŠã•ã‚ŒãŸå ´åˆ
                    st.session_state.selected_industries_import = industry_options_import.copy()
                elif "ã™ã¹ã¦" not in selected and "ã™ã¹ã¦" in st.session_state.selected_industries_import:
                    # ã€Œã™ã¹ã¦ã€ãŒè§£é™¤ã•ã‚ŒãŸå ´åˆ
                    st.session_state.selected_industries_import = []
                elif "ã™ã¹ã¦" in selected:
                    # ã€Œã™ã¹ã¦ã€ãŒé¸æŠã•ã‚Œã¦ã„ã‚‹çŠ¶æ…‹ã§ä»–ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆ
                    if len(selected) < len(industry_options_import):
                        # ä¸€éƒ¨è§£é™¤ã•ã‚ŒãŸå ´åˆã€ã€Œã™ã¹ã¦ã€ã‚’é™¤å¤–
                        st.session_state.selected_industries_import = [opt for opt in selected if opt != "ã™ã¹ã¦"]
                else:
                    # é€šå¸¸ã®é¸æŠ
                    st.session_state.selected_industries_import = selected
                    # å…¨ã¦é¸æŠã•ã‚Œã¦ã„ã‚‹å ´åˆã€ã€Œã™ã¹ã¦ã€ã‚’è¿½åŠ 
                    if len(selected) == len(industry_options_import) - 1:
                        st.session_state.selected_industries_import = ["ã™ã¹ã¦"] + selected
            
            target_industries = st.multiselect(
                "æ¥­ç¨®",
                options=industry_options_import,
                default=st.session_state.selected_industries_import,
                key="target_industries_multi",
                on_change=on_industries_import_change,
                help="è¤‡æ•°é¸æŠå¯èƒ½ã§ã™ã€‚ã€Œã™ã¹ã¦ã€ã‚’é¸æŠã™ã‚‹ã¨å…¨æ¥­ç¨®ãŒå¯¾è±¡ã«ãªã‚Šã¾ã™ã€‚"
            )
        
        with col_target2:
            # è·ç¨®ã®é¸æŠè‚¢ï¼ˆå³å´ã‚µã‚¤ãƒ‰ãƒãƒ¼ã¨åŒã˜31è·ç¨®ï¼‰
            job_title_options_import = ["ã™ã¹ã¦", "CTO", "VPoE", "EM", "ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "ã‚¤ãƒ³ãƒ•ãƒ©ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "ãƒ•ãƒ«ã‚¹ã‚¿ãƒƒã‚¯ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "ãƒ¢ãƒã‚¤ãƒ«ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ»ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆ", "ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆ", "æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ ", "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "UXã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "ãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼", "å­¦ç”Ÿ", "ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªã‚¹ãƒˆ", "CPO", "VPoT/VPoP", "ãƒ†ãƒƒã‚¯ãƒªãƒ¼ãƒ‰", "ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "SRE", "ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼", "DevOpsã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "QAã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "æ©Ÿæ¢°å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼", "SIer", "ã‚²ãƒ¼ãƒ é–‹ç™ºã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "çµ„ã¿è¾¼ã¿ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ä»¥å¤–", "ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢"]
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
            if 'selected_job_titles_import' not in st.session_state:
                st.session_state.selected_job_titles_import = ["ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢"]
            
            # ã€Œã™ã¹ã¦ã€é¸æŠã®å‡¦ç†
            def on_job_titles_import_change():
                selected = st.session_state.target_job_titles_multi
                if "ã™ã¹ã¦" in selected and "ã™ã¹ã¦" not in st.session_state.selected_job_titles_import:
                    st.session_state.selected_job_titles_import = job_title_options_import.copy()
                elif "ã™ã¹ã¦" not in selected and "ã™ã¹ã¦" in st.session_state.selected_job_titles_import:
                    st.session_state.selected_job_titles_import = []
                elif "ã™ã¹ã¦" in selected:
                    if len(selected) < len(job_title_options_import):
                        st.session_state.selected_job_titles_import = [opt for opt in selected if opt != "ã™ã¹ã¦"]
                else:
                    st.session_state.selected_job_titles_import = selected
                    if len(selected) == len(job_title_options_import) - 1:
                        st.session_state.selected_job_titles_import = ["ã™ã¹ã¦"] + selected
            
            target_job_titles = st.multiselect(
                "è·ç¨®",
                options=job_title_options_import,
                default=st.session_state.selected_job_titles_import,
                key="target_job_titles_multi",
                on_change=on_job_titles_import_change,
                help="è¤‡æ•°é¸æŠå¯èƒ½ã§ã™ã€‚ã€Œã™ã¹ã¦ã€ã‚’é¸æŠã™ã‚‹ã¨å…¨è·ç¨®ãŒå¯¾è±¡ã«ãªã‚Šã¾ã™ã€‚"
            )
        
        with col_target3:
            # å¾“æ¥­å“¡è¦æ¨¡ã®é¸æŠè‚¢ï¼ˆå³å´ã‚µã‚¤ãƒ‰ãƒãƒ¼ã¨åŒã˜8æ®µéšï¼‰
            company_size_options_import = ["ã™ã¹ã¦", "10åä»¥ä¸‹", "11åï½50å", "51åï½100å", "101åï½300å", "301åï½500å", "501åï½1,000å", "1,001ï½5,000å", "5,001åä»¥ä¸Š"]
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
            if 'selected_company_sizes_import' not in st.session_state:
                st.session_state.selected_company_sizes_import = ["101åï½300å", "301åï½500å"]
            
            # ã€Œã™ã¹ã¦ã€é¸æŠã®å‡¦ç†
            def on_company_sizes_import_change():
                selected = st.session_state.target_company_sizes_multi
                if "ã™ã¹ã¦" in selected and "ã™ã¹ã¦" not in st.session_state.selected_company_sizes_import:
                    st.session_state.selected_company_sizes_import = company_size_options_import.copy()
                elif "ã™ã¹ã¦" not in selected and "ã™ã¹ã¦" in st.session_state.selected_company_sizes_import:
                    st.session_state.selected_company_sizes_import = []
                elif "ã™ã¹ã¦" in selected:
                    if len(selected) < len(company_size_options_import):
                        st.session_state.selected_company_sizes_import = [opt for opt in selected if opt != "ã™ã¹ã¦"]
                else:
                    st.session_state.selected_company_sizes_import = selected
                    if len(selected) == len(company_size_options_import) - 1:
                        st.session_state.selected_company_sizes_import = ["ã™ã¹ã¦"] + selected
            
            target_company_sizes = st.multiselect(
                "å¾“æ¥­å“¡è¦æ¨¡",
                options=company_size_options_import,
                default=st.session_state.selected_company_sizes_import,
                key="target_company_sizes_multi",
                on_change=on_company_sizes_import_change,
                help="è¤‡æ•°é¸æŠå¯èƒ½ã§ã™ã€‚ã€Œã™ã¹ã¦ã€ã‚’é¸æŠã™ã‚‹ã¨å…¨è¦æ¨¡ãŒå¯¾è±¡ã«ãªã‚Šã¾ã™ã€‚"
            )
        
        st.divider()
        
        # b. é›†å®¢æ–½ç­–ä¸€è¦§ã¨å®Ÿç¸¾ï¼ˆCSVï¼‰
        st.markdown("#### ğŸ“Š b. é›†å®¢æ–½ç­–ä¸€è¦§ã¨å®Ÿç¸¾ï¼ˆCSVã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰")
        
        with st.expander("ğŸ“‹ CSVãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä»•æ§˜", expanded=False):
            st.markdown("""
            **å¿…é ˆåˆ—:**
            - `æ–½ç­–å` ã¾ãŸã¯ `Campaign Name` - é›†å®¢æ–½ç­–ã®åå‰
            - `ãƒªãƒ¼ãƒæ•°` ã¾ãŸã¯ `Reach` - ãƒªãƒ¼ãƒæ•°
            - `CTR` - ã‚¯ãƒªãƒƒã‚¯ç‡ï¼ˆ%ï¼‰
            - `CVR` - ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç‡ï¼ˆ%ï¼‰
            - `CVæ•°` ã¾ãŸã¯ `Conversions` - ç”³è¾¼è€…æ•°
            - `è²»ç”¨` ã¾ãŸã¯ `Cost` - æ–½ç­–è²»ç”¨ï¼ˆå††ï¼‰
            - `CPA` - ç²å¾—å˜ä¾¡ï¼ˆå††ï¼‰
            
            **CSVã‚µãƒ³ãƒ—ãƒ«:**
            ```
            æ–½ç­–å,ãƒªãƒ¼ãƒæ•°,CTR,CVR,CVæ•°,è²»ç”¨,CPA
            Googleåºƒå‘Š,50000,3.5,2.8,49,200000,4082
            Facebookåºƒå‘Š,30000,2.8,3.2,27,150000,5556
            ãƒ¡ãƒ¼ãƒ«ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°,10000,5.0,4.0,20,0,0
            ```
            """)
        
        uploaded_campaign_csv = st.file_uploader(
            "ğŸ“Š é›†å®¢æ–½ç­–å®Ÿç¸¾CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
            type=['csv'],
            key="campaign_results_csv",
            help="é›†å®¢æ–½ç­–ã®å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€CSVãƒ•ã‚¡ã‚¤ãƒ«"
        )
        
        st.divider()
        
        # c. ç”³è¾¼è€…æƒ…å ±ï¼ˆCSVï¼‰
        st.markdown("#### ğŸ‘¥ c. ç”³è¾¼è€…æƒ…å ±ï¼ˆCSVã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰")
        
        with st.expander("ğŸ“‹ CSVãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä»•æ§˜", expanded=False):
            st.markdown("""
            **å¿…é ˆåˆ—:**
            - `å½¹è·` ã¾ãŸã¯ `Position` - ç”³è¾¼è€…ã®å½¹è·
            - `è·ç¨®` ã¾ãŸã¯ `Job Title` - ç”³è¾¼è€…ã®è·ç¨®
            - `ä¼æ¥­å` ã¾ãŸã¯ `Company` - ç”³è¾¼è€…ã®ä¼æ¥­å
            - `æ¥­ç¨®` ã¾ãŸã¯ `Industry` - ç”³è¾¼è€…ã®æ¥­ç¨®
            - `å¾“æ¥­å“¡è¦æ¨¡` ã¾ãŸã¯ `Company Size` - ç”³è¾¼è€…ã®ä¼æ¥­è¦æ¨¡
            
            **CSVã‚µãƒ³ãƒ—ãƒ«:**
            ```
            å½¹è·,è·ç¨®,ä¼æ¥­å,æ¥­ç¨®,å¾“æ¥­å“¡è¦æ¨¡
            éƒ¨é•·,ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢,æ ªå¼ä¼šç¤¾ãƒ†ãƒƒã‚¯,æƒ…å ±ãƒ»é€šä¿¡æ¥­,101åï½300å
            ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼,ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆ,ãƒ‡ãƒ¼ã‚¿æ ªå¼ä¼šç¤¾,æƒ…å ±ãƒ»é€šä¿¡æ¥­,51åï½100å
            å–ç· å½¹,ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼,ã‚³ãƒ³ã‚µãƒ«ç¤¾,ã‚µãƒ¼ãƒ“ã‚¹æ¥­,1,001ï½5,000å
            ```
            """)
        
        uploaded_applicant_csv = st.file_uploader(
            "ğŸ“Š ç”³è¾¼è€…æƒ…å ±CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
            type=['csv'],
            key="applicant_info_csv",
            help="ç”³è¾¼è€…ã®è©³ç´°æƒ…å ±ã‚’å«ã‚€CSVãƒ•ã‚¡ã‚¤ãƒ«"
        )
        
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå‡¦ç†
        if uploaded_applicant_csv is not None:
            # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½
            if st.button("ğŸ‘€ ç”³è¾¼è€…ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", key="preview_conference_csv"):
                try:
                    import tempfile
                    import os
                    
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp_file:
                        tmp_file.write(uploaded_applicant_csv.getvalue())
                        tmp_file_path = tmp_file.name
                    
                    # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
                    df_preview = pd.read_csv(tmp_file_path, encoding='utf-8-sig')
                    st.markdown("**ğŸ“‹ ç”³è¾¼è€…ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆã®5è¡Œï¼‰:**")
                    st.dataframe(df_preview.head(), use_container_width=True)
                    st.info(f"ğŸ“Š {len(df_preview)}è¡Œ x {len(df_preview.columns)}åˆ—ã®ç”³è¾¼è€…ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œå‡º")
                    
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                    os.unlink(tmp_file_path)
                    
                except Exception as e:
                    st.error(f"âŒ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ
        col_import1, col_import2 = st.columns(2)
        
        with col_import1:
            if st.button("ğŸ“¥ ã‚¤ãƒ™ãƒ³ãƒˆå®Ÿç¸¾ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ", type="primary", key="import_conference_data"):
                # åŸºæœ¬æƒ…å ±ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
                if not event_name.strip():
                    st.error("âŒ ã‚¤ãƒ™ãƒ³ãƒˆåã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                elif not event_theme.strip():
                    st.error("âŒ ãƒ†ãƒ¼ãƒã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                elif not target_industries and not target_job_titles and not target_company_sizes:
                    st.error("âŒ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’æœ€ä½ä¸€ã¤é¸æŠã—ã¦ãã ã•ã„")
                elif uploaded_applicant_csv is None:
                    st.error("âŒ ç”³è¾¼è€…ãƒ‡ãƒ¼ã‚¿CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
                else:
                    with st.spinner("ğŸ† ã‚¤ãƒ™ãƒ³ãƒˆå®Ÿç¸¾ã‚’å‡¦ç†ä¸­..."):
                        try:
                            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæƒ…å ±ã‚’çµåˆï¼ˆã€Œã™ã¹ã¦ã€ã‚’é™¤å¤–ã—ã¦å®Ÿéš›ã®å€¤ã®ã¿ä½¿ç”¨ï¼‰
                            target_info = []
                            
                            # æ¥­ç¨®ã®å‡¦ç†
                            industries_actual = [x for x in target_industries if x != "ã™ã¹ã¦"] if "ã™ã¹ã¦" not in target_industries else [x for x in industry_options_import if x != "ã™ã¹ã¦"]
                            if industries_actual:
                                target_info.extend([f"æ¥­ç¨®:{x}" for x in industries_actual])
                            
                            # è·ç¨®ã®å‡¦ç†
                            job_titles_actual = [x for x in target_job_titles if x != "ã™ã¹ã¦"] if "ã™ã¹ã¦" not in target_job_titles else [x for x in job_title_options_import if x != "ã™ã¹ã¦"]
                            if job_titles_actual:
                                target_info.extend([f"è·ç¨®:{x}" for x in job_titles_actual])
                            
                            # å¾“æ¥­å“¡è¦æ¨¡ã®å‡¦ç†
                            company_sizes_actual = [x for x in target_company_sizes if x != "ã™ã¹ã¦"] if "ã™ã¹ã¦" not in target_company_sizes else [x for x in company_size_options_import if x != "ã™ã¹ã¦"]
                            if company_sizes_actual:
                                target_info.extend([f"å¾“æ¥­å“¡è¦æ¨¡:{x}" for x in company_sizes_actual])
                            
                            # åŸºæœ¬æƒ…å ±ã‚’æ•´ç†
                            event_info = {
                                "event_name": event_name.strip(),
                                "theme": event_theme.strip(),
                                "category": event_category,
                                "target": ", ".join(target_info),
                                "target_attendees": 0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                                "budget": 0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                                "event_date": str(event_date)
                            }
                            
                            # CSVå‡¦ç†
                            import tempfile
                            import os
                            
                            with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp_file:
                                tmp_file.write(uploaded_applicant_csv.getvalue())
                                tmp_file_path = tmp_file.name
                            
                            # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ
                            result = process_conference_import(tmp_file_path, event_info, data_system)
                            
                            # çµæœè¡¨ç¤º
                            if result["success"]:
                                st.success(f"âœ… ã‚¤ãƒ™ãƒ³ãƒˆå®Ÿç¸¾ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸï¼")
                                st.info(f"ğŸ“Š ã‚¤ãƒ™ãƒ³ãƒˆ: {event_info['event_name']}")
                                st.info(f"ğŸ‘¥ ç”³è¾¼è€…ãƒ‡ãƒ¼ã‚¿: {result.get('applicant_count', 0)}ä»¶")
                                
                                if result.get("errors"):
                                    st.warning(f"âš ï¸ {len(result['errors'])}ä»¶ã®ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Šã¾ã—ãŸ:")
                                    with st.expander("ã‚¨ãƒ©ãƒ¼è©³ç´°"):
                                        for error in result["errors"]:
                                            st.write(f"- {error}")
                            else:
                                st.error(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
                            
                            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                            os.unlink(tmp_file_path)
                            
                        except Exception as e:
                            st.error(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        with col_import2:
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            template_csv = """è·ç¨®,å½¹è·,ä¼æ¥­å,æ¥­ç¨®,å¾“æ¥­å“¡è¦æ¨¡
ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢,ã‚·ãƒ‹ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢,æ ªå¼ä¼šç¤¾ãƒ†ãƒƒã‚¯,æƒ…å ±ãƒ»é€šä¿¡æ¥­,301åï½500å
ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆ,ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼,ãƒ‡ãƒ¼ã‚¿æ ªå¼ä¼šç¤¾,æƒ…å ±ãƒ»é€šä¿¡æ¥­,101åï½300å
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼,éƒ¨é•·,ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆç¤¾,è£½é€ æ¥­,1,001ï½5,000å
ãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼,èª²é•·,ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ç¤¾,ã‚µãƒ¼ãƒ“ã‚¹æ¥­,101åï½300å
CTO,å–ç· å½¹,ãƒ†ãƒƒã‚¯ç¤¾,æƒ…å ±ãƒ»é€šä¿¡æ¥­,501åï½1,000å
"""
            st.download_button(
                label="ğŸ“„ ç”³è¾¼è€…ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=template_csv,
                file_name="conference_applicants_template.csv",
                mime="text/csv"
            )
    
    with tab2:
        # æœ‰å„Ÿãƒ¡ãƒ‡ã‚£ã‚¢ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        st.markdown("##### ğŸ’° æœ‰å„Ÿãƒ¡ãƒ‡ã‚£ã‚¢ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
        
        # æ‰‹å…¥åŠ›ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        st.markdown("#### ğŸ“ åŸºæœ¬æƒ…å ±ï¼ˆæ‰‹å…¥åŠ›ï¼‰")
        col1, col2 = st.columns(2)
        
        with col1:
            paid_media_event_name = st.text_input("ã‚¤ãƒ™ãƒ³ãƒˆå", key="paid_event_name", 
                                                placeholder="ä¾‹ï¼šAIæŠ€è¡“ã‚«ãƒ³ãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ 2025")
            paid_media_theme = st.text_input("ã‚¤ãƒ™ãƒ³ãƒˆãƒ†ãƒ¼ãƒ", key="paid_theme", 
                                           placeholder="ä¾‹ï¼šæ¬¡ä¸–ä»£AIæŠ€è¡“")
        
        with col2:
            paid_media_category = st.selectbox("ã‚¤ãƒ™ãƒ³ãƒˆã‚«ãƒ†ã‚´ãƒª", 
                                             ["conference", "seminar", "workshop", "webinar", "networking", "product_launch"],
                                             format_func=lambda x: {
                                                 "conference": "ã‚«ãƒ³ãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹",
                                                 "seminar": "ã‚»ãƒŸãƒŠãƒ¼", 
                                                 "workshop": "ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—",
                                                 "webinar": "ã‚¦ã‚§ãƒ“ãƒŠãƒ¼",
                                                 "networking": "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚­ãƒ³ã‚°",
                                                 "product_launch": "è£½å“ç™ºè¡¨"
                                             }[x],
                                             key="paid_category")
            paid_media_target = st.text_input("ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆ", key="paid_target", 
                                            placeholder="ä¾‹ï¼šçµŒå–¶è€…ãƒ»ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼")
        
        # è¿½åŠ æƒ…å ±
        col3, col4, col5 = st.columns(3)
        with col3:
            paid_media_name = st.text_input("æœ‰å„Ÿãƒ¡ãƒ‡ã‚£ã‚¢å", key="paid_media_name", 
                                          placeholder="ä¾‹ï¼šæ—¥çµŒãƒ“ã‚¸ãƒã‚¹")
        with col4:
            paid_media_cost = st.number_input("æ²è¼‰æ–™é‡‘ï¼ˆå††ï¼‰", min_value=0, value=0, key="paid_cost")
        with col5:
            paid_media_date = st.date_input("æ²è¼‰æ—¥", key="paid_date")
        
        st.divider()
        
        # CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        st.markdown("#### ğŸ“Š ç”³è¾¼è€…è©³ç´°ãƒ‡ãƒ¼ã‚¿ï¼ˆCSVã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰")
        
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆèª¬æ˜
        with st.expander("ğŸ“‹ CSVãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä»•æ§˜", expanded=False):
            st.markdown("""
            **å¿…é ˆåˆ—:**
            - `è·ç¨®` ã¾ãŸã¯ `Job Title` - ç”³è¾¼è€…ã®è·ç¨®
            - `å½¹è·` ã¾ãŸã¯ `Position` - ç”³è¾¼è€…ã®å½¹è·
            - `ä¼æ¥­å` ã¾ãŸã¯ `Company` - ç”³è¾¼è€…ã®ä¼æ¥­å
            - `æ¥­ç¨®` ã¾ãŸã¯ `Industry` - ç”³è¾¼è€…ã®æ¥­ç¨®
            - `å¾“æ¥­å“¡è¦æ¨¡` ã¾ãŸã¯ `Company Size` - ç”³è¾¼è€…ã®ä¼æ¥­è¦æ¨¡
            
            **æ¨å¥¨åˆ—:**
            - `ç”³è¾¼çµŒè·¯` ã¾ãŸã¯ `Source` - ç”³è¾¼çµŒè·¯ï¼ˆæœ‰å„Ÿãƒ¡ãƒ‡ã‚£ã‚¢åï¼‰
            - `ç”³è¾¼æ—¥` ã¾ãŸã¯ `Apply Date` - ç”³è¾¼æ—¥
            
            **CSVã‚µãƒ³ãƒ—ãƒ«:**
            ```
            è·ç¨®,å½¹è·,ä¼æ¥­å,æ¥­ç¨®,å¾“æ¥­å“¡è¦æ¨¡,ç”³è¾¼çµŒè·¯,ç”³è¾¼æ—¥
            CTO,å–ç· å½¹,ãƒ†ãƒƒã‚¯æ ªå¼ä¼šç¤¾,æƒ…å ±ãƒ»é€šä¿¡æ¥­,301åï½500å,æ—¥çµŒãƒ“ã‚¸ãƒã‚¹,2025-01-10
            ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼,éƒ¨é•·,ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ç¤¾,ã‚µãƒ¼ãƒ“ã‚¹æ¥­,101åï½300å,æ—¥çµŒãƒ“ã‚¸ãƒã‚¹,2025-01-11
            ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆ,ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼,ã‚³ãƒ³ã‚µãƒ«ç¤¾,ã‚µãƒ¼ãƒ“ã‚¹æ¥­,501åï½1,000å,æ—¥çµŒãƒ“ã‚¸ãƒã‚¹,2025-01-12
            ```
            """)
        
        # CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        uploaded_paid_media_csv = st.file_uploader(
            "ğŸ“Š æœ‰å„Ÿãƒ¡ãƒ‡ã‚£ã‚¢çµŒç”±ç”³è¾¼è€…ãƒ‡ãƒ¼ã‚¿CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
            type=['csv'],
            key="paid_media_applicant_csv",
            help="æœ‰å„Ÿãƒ¡ãƒ‡ã‚£ã‚¢çµŒç”±ã®ç”³è¾¼è€…ã®è·ç¨®ã€å½¹è·ã€ä¼æ¥­åã€æ¥­ç¨®ã€å¾“æ¥­å“¡è¦æ¨¡ã‚’å«ã‚€CSVãƒ•ã‚¡ã‚¤ãƒ«"
        )
        
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå‡¦ç†
        if uploaded_paid_media_csv is not None:
            # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½
            if st.button("ğŸ‘€ ç”³è¾¼è€…ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", key="preview_paid_media_csv"):
                try:
                    import tempfile
                    import os
                    
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp_file:
                        tmp_file.write(uploaded_paid_media_csv.getvalue())
                        tmp_file_path = tmp_file.name
                    
                    # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
                    df_preview = pd.read_csv(tmp_file_path, encoding='utf-8-sig')
                    st.markdown("**ğŸ“‹ ç”³è¾¼è€…ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆã®5è¡Œï¼‰:**")
                    st.dataframe(df_preview.head(), use_container_width=True)
                    st.info(f"ğŸ“Š {len(df_preview)}è¡Œ x {len(df_preview.columns)}åˆ—ã®ç”³è¾¼è€…ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œå‡º")
                    
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                    os.unlink(tmp_file_path)
                    
                except Exception as e:
                    st.error(f"âŒ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ
        col_import1, col_import2 = st.columns(2)
        
        with col_import1:
            if st.button("ğŸ“¥ æœ‰å„Ÿãƒ¡ãƒ‡ã‚£ã‚¢å®Ÿç¸¾ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ", type="primary", key="import_paid_media_data"):
                # åŸºæœ¬æƒ…å ±ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
                if not paid_media_event_name.strip():
                    st.error("âŒ ã‚¤ãƒ™ãƒ³ãƒˆåã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                elif not paid_media_theme.strip():
                    st.error("âŒ ã‚¤ãƒ™ãƒ³ãƒˆãƒ†ãƒ¼ãƒã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                elif not paid_media_target.strip():
                    st.error("âŒ ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                elif not paid_media_name.strip():
                    st.error("âŒ æœ‰å„Ÿãƒ¡ãƒ‡ã‚£ã‚¢åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                elif uploaded_paid_media_csv is None:
                    st.error("âŒ ç”³è¾¼è€…ãƒ‡ãƒ¼ã‚¿CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
                else:
                    with st.spinner("ğŸ’° æœ‰å„Ÿãƒ¡ãƒ‡ã‚£ã‚¢å®Ÿç¸¾ã‚’å‡¦ç†ä¸­..."):
                        try:
                            # åŸºæœ¬æƒ…å ±ã‚’æ•´ç†
                            media_info = {
                                "event_name": paid_media_event_name.strip(),
                                "event_theme": paid_media_theme.strip(),
                                "event_category": paid_media_category,
                                "event_target": paid_media_target.strip(),
                                "media_name": paid_media_name.strip(),
                                "media_cost": paid_media_cost,
                                "media_date": str(paid_media_date)
                            }
                            
                            # CSVå‡¦ç†
                            import tempfile
                            import os
                            
                            with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp_file:
                                tmp_file.write(uploaded_paid_media_csv.getvalue())
                                tmp_file_path = tmp_file.name
                            
                            # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ
                            result = process_paid_media_import(tmp_file_path, media_info, data_system)
                            
                            # çµæœè¡¨ç¤º
                            if result["success"]:
                                st.success(f"âœ… æœ‰å„Ÿãƒ¡ãƒ‡ã‚£ã‚¢å®Ÿç¸¾ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸï¼")
                                st.info(f"ğŸ“Š ã‚¤ãƒ™ãƒ³ãƒˆ: {media_info['event_name']}")
                                st.info(f"ğŸ’° ãƒ¡ãƒ‡ã‚£ã‚¢: {media_info['media_name']}")
                                st.info(f"ğŸ‘¥ ç”³è¾¼è€…ãƒ‡ãƒ¼ã‚¿: {result.get('applicant_count', 0)}ä»¶")
                                
                                if result.get("errors"):
                                    st.warning(f"âš ï¸ {len(result['errors'])}ä»¶ã®ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Šã¾ã—ãŸ:")
                                    with st.expander("ã‚¨ãƒ©ãƒ¼è©³ç´°"):
                                        for error in result["errors"]:
                                            st.write(f"- {error}")
                            else:
                                st.error(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
                            
                            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                            os.unlink(tmp_file_path)
                            
                        except Exception as e:
                            st.error(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        with col_import2:
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            template_csv = """è·ç¨®,å½¹è·,ä¼æ¥­å,æ¥­ç¨®,å¾“æ¥­å“¡è¦æ¨¡,ç”³è¾¼çµŒè·¯,ç”³è¾¼æ—¥
CTO,å–ç· å½¹,ãƒ†ãƒƒã‚¯æ ªå¼ä¼šç¤¾,æƒ…å ±ãƒ»é€šä¿¡æ¥­,301åï½500å,æ—¥çµŒãƒ“ã‚¸ãƒã‚¹,2025-01-10
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼,éƒ¨é•·,ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ç¤¾,ã‚µãƒ¼ãƒ“ã‚¹æ¥­,101åï½300å,æ—¥çµŒãƒ“ã‚¸ãƒã‚¹,2025-01-11
ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆ,ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼,ã‚³ãƒ³ã‚µãƒ«ç¤¾,ã‚µãƒ¼ãƒ“ã‚¹æ¥­,501åï½1,000å,æ—¥çµŒãƒ“ã‚¸ãƒã‚¹,2025-01-12
ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢,ã‚·ãƒ‹ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢,ãƒ•ã‚£ãƒ³ãƒ†ãƒƒã‚¯ç¤¾,éŠ€è¡Œæ¥­,1,001ï½5,000å,æ—¥çµŒãƒ“ã‚¸ãƒã‚¹,2025-01-13
"""
            st.download_button(
                label="ğŸ“„ æœ‰å„Ÿãƒ¡ãƒ‡ã‚£ã‚¢ç”³è¾¼è€…ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=template_csv,
                file_name="paid_media_applicants_template.csv",
                mime="text/csv"
            )
        
        st.divider()
        
        # WEBåºƒå‘Šãƒ»åª’ä½“æƒ…å ±ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        st.markdown("##### ğŸŒ WEBåºƒå‘Šãƒ»åª’ä½“æƒ…å ±ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼é¸æŠ
        web_ad_format = st.selectbox(
            "ğŸ“ ã‚¤ãƒ³ãƒãƒ¼ãƒˆå½¢å¼ã‚’é¸æŠ",
            ["CSV", "PDF", "PowerPoint (PPT/PPTX)"],
            key="web_ad_format_select"
        )
        
        if web_ad_format == "CSV":
            # CSVãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆèª¬æ˜
            with st.expander("ğŸ“‹ CSVãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä»•æ§˜", expanded=False):
                st.markdown("""
                **å¿…é ˆåˆ—:**
                - `åºƒå‘Šå` ã¾ãŸã¯ `Ad Name` - WEBåºƒå‘Šã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å
                - `ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ` ã¾ãŸã¯ `Platform` - åºƒå‘Šãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ï¼ˆGoogleã€Metaã€Yahooç­‰ï¼‰
                
                **æ¨å¥¨åˆ—:**
                - `åºƒå‘Šã‚¿ã‚¤ãƒ—` ã¾ãŸã¯ `Ad Type` - åºƒå‘Šã®ç¨®é¡ï¼ˆæ¤œç´¢åºƒå‘Šã€ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤åºƒå‘Šã€SNSåºƒå‘Šç­‰ï¼‰
                - `å¯¾è±¡èª­è€…` ã¾ãŸã¯ `Target Audience` - ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚ªãƒ¼ãƒ‡ã‚£ã‚¨ãƒ³ã‚¹
                - `CTR` - ã‚¯ãƒªãƒƒã‚¯ç‡ï¼ˆ%ï¼‰
                - `CVR` - ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç‡ï¼ˆ%ï¼‰
                - `CPC` - ã‚¯ãƒªãƒƒã‚¯å˜ä¾¡ï¼ˆå††ï¼‰
                - `CPA` - ç²å¾—å˜ä¾¡ï¼ˆå††ï¼‰
                - `ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³` ã¾ãŸã¯ `Impressions` - ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°
                - `é…ä¿¡æœŸé–“` ã¾ãŸã¯ `Duration` - é…ä¿¡æœŸé–“
                - `äºˆç®—` ã¾ãŸã¯ `Budget` - åºƒå‘Šäºˆç®—
                
                **CSVã‚µãƒ³ãƒ—ãƒ«:**
                ```
                åºƒå‘Šå,ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ,åºƒå‘Šã‚¿ã‚¤ãƒ—,å¯¾è±¡èª­è€…,CTR,CVR,CPC,CPA,ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³,é…ä¿¡æœŸé–“,äºˆç®—
                AIæŠ€è¡“ã‚»ãƒŸãƒŠãƒ¼æ¤œç´¢åºƒå‘Š,Google,æ¤œç´¢åºƒå‘Š,ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢,3.5,2.8,120,4200,50000,2é€±é–“,300000
                ```
                """)
            
            uploaded_web_ad_csv = st.file_uploader(
                "ğŸ“Š WEBåºƒå‘Šãƒ‡ãƒ¼ã‚¿CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
                type=['csv'],
                key="web_ad_csv_upload"
            )
            
            if uploaded_web_ad_csv is not None:
                if st.button("ğŸ“¥ WEBåºƒå‘ŠCSVã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ", type="primary", key="import_web_ad_csv"):
                    process_web_ad_csv_import(uploaded_web_ad_csv, data_system)
        
        elif web_ad_format == "PDF":
            # PDFèª¬æ˜
            st.markdown("""
            **ğŸ“„ PDFã‹ã‚‰ã®æƒ…å ±æŠ½å‡º:**
            - WEBåºƒå‘Šã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³æƒ…å ±
            - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿
            - åºƒå‘Šé‹ç”¨å®Ÿç¸¾ã‚„åŠ¹æœæ¸¬å®š
            """)
            
            uploaded_web_ad_pdf = st.file_uploader(
                "ğŸ“„ WEBåºƒå‘Šæƒ…å ±PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
                type=['pdf'],
                key="web_ad_pdf_upload"
            )
            
            if uploaded_web_ad_pdf is not None:
                if st.button("ğŸ“¥ WEBåºƒå‘ŠPDFã‚’è§£æãƒ»ã‚¤ãƒ³ãƒãƒ¼ãƒˆ", type="primary", key="import_web_ad_pdf"):
                    process_media_pdf_import(uploaded_web_ad_pdf, data_system)
        
        elif web_ad_format == "PowerPoint (PPT/PPTX)":
            # PowerPointèª¬æ˜
            st.markdown("""
            **ğŸ“Š PowerPointã‹ã‚‰ã®æƒ…å ±æŠ½å‡º:**
            - åºƒå‘Šãƒ¬ãƒãƒ¼ãƒˆè³‡æ–™ã®æƒ…å ±
            - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿è¡¨ãƒ»ã‚°ãƒ©ãƒ•
            - åºƒå‘Šé‹ç”¨çµæœã‚„åˆ†æãƒ‡ãƒ¼ã‚¿
            """)
            
            uploaded_web_ad_ppt = st.file_uploader(
                "ğŸ“Š WEBåºƒå‘Šæƒ…å ±PowerPointãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
                type=['ppt', 'pptx'],
                key="web_ad_ppt_upload"
            )
            
            if uploaded_web_ad_ppt is not None:
                if st.button("ğŸ“¥ PowerPointã‚’è§£æãƒ»ã‚¤ãƒ³ãƒãƒ¼ãƒˆ", type="primary", key="import_web_ad_ppt"):
                    process_media_ppt_import(uploaded_web_ad_ppt, data_system)
    
    with tab3:
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå±¥æ­´ãƒ»çµ±è¨ˆ
        st.markdown("##### ğŸ“Š ã‚¤ãƒ³ãƒãƒ¼ãƒˆå±¥æ­´ãƒ»çµ±è¨ˆ")
        show_import_history_and_stats(data_system)

def process_media_csv_import(uploaded_file, data_system):
    """ãƒ¡ãƒ‡ã‚£ã‚¢CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆå‡¦ç†"""
    with st.spinner("ğŸ“Š ãƒ¡ãƒ‡ã‚£ã‚¢CSVãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­..."):
        try:
            import tempfile
            import os
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_file_path = tmp_file.name
            
            # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ
            result = data_system.import_existing_csv(tmp_file_path, "media")
            
            # çµæœè¡¨ç¤º
            if result["success"]:
                st.success(f"âœ… {result['imported']}ä»¶ã®ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸï¼")
            else:
                st.error(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {result['error']}")
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            os.unlink(tmp_file_path)
            
        except Exception as e:
            st.error(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")

def process_media_pdf_import(uploaded_file, data_system):
    """ãƒ¡ãƒ‡ã‚£ã‚¢PDFã‚¤ãƒ³ãƒãƒ¼ãƒˆå‡¦ç†"""
    with st.spinner("ğŸ“„ PDFã‚’è§£æä¸­..."):
        try:
            import tempfile
            import os
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_file_path = tmp_file.name
            
            # PDFè§£æå®Ÿè¡Œ
            result = data_system.extract_pdf_insights(tmp_file_path)
            
            # çµæœè¡¨ç¤º
            if result["success"]:
                st.success("âœ… PDFã®è§£æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("æŠ½å‡ºã•ã‚ŒãŸãƒ¡ãƒ‡ã‚£ã‚¢æƒ…å ±", f"{result.get('media_extracted', 0)}ä»¶")
                with col2:
                    st.metric("æŠ½å‡ºã•ã‚ŒãŸçŸ¥è¦‹", f"{result.get('insights_extracted', 0)}ä»¶")
                
                if result.get('analysis_method'):
                    st.info(f"ğŸ”¬ è§£ææ–¹æ³•: {result['analysis_method']}")
                
                if result.get('confidence'):
                    st.info(f"ğŸ¯ è§£æä¿¡é ¼åº¦: {result['confidence']*100:.1f}%")
            else:
                st.error(f"âŒ PDFè§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {result['error']}")
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            os.unlink(tmp_file_path)
            
        except Exception as e:
            st.error(f"âŒ PDFè§£æã‚¨ãƒ©ãƒ¼: {str(e)}")

def process_media_ppt_import(uploaded_file, data_system):
    """PowerPointã‚¤ãƒ³ãƒãƒ¼ãƒˆå‡¦ç†"""
    with st.spinner("ğŸ“Š PowerPointã‚’è§£æä¸­..."):
        try:
            import tempfile
            import os
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with tempfile.NamedTemporaryFile(delete=False, suffix='.pptx') as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_file_path = tmp_file.name
            
            # PowerPointè§£æå®Ÿè¡Œ
            result = data_system.extract_pptx_insights(tmp_file_path)
            
            # çµæœè¡¨ç¤º
            if result["success"]:
                st.success("âœ… PowerPointã®è§£æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("æŠ½å‡ºã•ã‚ŒãŸãƒ¡ãƒ‡ã‚£ã‚¢æƒ…å ±", f"{result.get('media_extracted', 0)}ä»¶")
                with col2:
                    st.metric("æŠ½å‡ºã•ã‚ŒãŸçŸ¥è¦‹", f"{result.get('insights_extracted', 0)}ä»¶")
                
                if result.get('analysis_method'):
                    st.info(f"ğŸ”¬ è§£ææ–¹æ³•: {result['analysis_method']}")
                
                if result.get('confidence'):
                    st.info(f"ğŸ¯ è§£æä¿¡é ¼åº¦: {result['confidence']*100:.1f}%")
            else:
                st.error(f"âŒ PowerPointè§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {result['error']}")
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            os.unlink(tmp_file_path)
            
        except Exception as e:
            st.error(f"âŒ PowerPointè§£æã‚¨ãƒ©ãƒ¼: {str(e)}")

def process_knowledge_file_import(uploaded_file, file_format, data_system):
    """çŸ¥è¦‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆå‡¦ç†"""
    with st.spinner(f"ğŸ“„ {file_format}ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æä¸­..."):
        try:
            import tempfile
            import os
            
            if file_format == "Markdown (.md)":
                # Markdownå‡¦ç†
                content = uploaded_file.getvalue().decode('utf-8')
                result = process_markdown_knowledge(content, data_system)
                
            elif file_format == "PDF":
                # PDFå‡¦ç†
                with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                    tmp_file_path = tmp_file.name
                
                result = data_system.extract_pdf_insights(tmp_file_path)
                os.unlink(tmp_file_path)
                
            elif file_format == "Wordæ–‡æ›¸ (.docx)":
                # Wordæ–‡æ›¸å‡¦ç†
                with tempfile.NamedTemporaryFile(delete=False, suffix='.docx') as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                    tmp_file_path = tmp_file.name
                
                result = data_system.extract_docx_insights(tmp_file_path)
                os.unlink(tmp_file_path)
                
            elif file_format == "ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« (.txt)":
                # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
                content = uploaded_file.getvalue().decode('utf-8')
                result = process_text_knowledge(content, data_system)
                
            else:
                # ãã®ä»–ã®å‡¦ç†ï¼ˆä»Šå¾Œå®Ÿè£…ï¼‰
                st.warning(f"ğŸš§ {file_format}è§£ææ©Ÿèƒ½ã¯é–‹ç™ºä¸­ã§ã™ã€‚ã¾ã‚‚ãªãå¯¾å¿œäºˆå®šã§ã™ï¼")
                return
            
            # çµæœè¡¨ç¤º
            if result.get("success"):
                st.success("âœ… ãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                
                if result.get('insights_extracted', 0) > 0:
                    st.metric("æŠ½å‡ºã•ã‚ŒãŸçŸ¥è¦‹", f"{result['insights_extracted']}ä»¶")
                
                if result.get('media_extracted', 0) > 0:
                    st.metric("æŠ½å‡ºã•ã‚ŒãŸãƒ¡ãƒ‡ã‚£ã‚¢æƒ…å ±", f"{result['media_extracted']}ä»¶")
                    
            else:
                st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
            
        except Exception as e:
            st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«è§£æã‚¨ãƒ©ãƒ¼: {str(e)}")

def process_markdown_knowledge(content, data_system):
    """Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰çŸ¥è¦‹ã‚’æŠ½å‡º"""
    try:
        # Markdownãƒ‘ãƒ¼ã‚¹ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        lines = content.split('\n')
        
        title = ""
        category = "general"
        impact_score = 0.7
        confidence = 0.8
        knowledge_content = ""
        
        current_section = ""
        
        for line in lines:
            line = line.strip()
            
            if line.startswith('# '):
                title = line[2:].strip()
            elif line.startswith('**ã‚«ãƒ†ã‚´ãƒª:**'):
                category = line.split(':')[1].strip()
            elif line.startswith('**å½±éŸ¿åº¦:**'):
                try:
                    impact_score = float(line.split(':')[1].strip())
                except:
                    pass
            elif line.startswith('**ä¿¡é ¼åº¦:**'):
                try:
                    confidence = float(line.split(':')[1].strip())
                except:
                    pass
            elif line.startswith('## '):
                current_section = line[3:].strip()
            elif line and not line.startswith('#') and not line.startswith('**'):
                knowledge_content += line + "\n"
        
        if title and knowledge_content:
            knowledge_id = data_system.add_manual_knowledge(
                category, title, knowledge_content.strip(),
                impact=impact_score
            )
            
            return {"success": True, "insights_extracted": 1, "knowledge_id": knowledge_id}
        else:
            return {"success": False, "error": "ã‚¿ã‚¤ãƒˆãƒ«ã¾ãŸã¯å†…å®¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"}
            
    except Exception as e:
        return {"success": False, "error": str(e)}

def show_import_history_and_stats(data_system):
    """ã‚¤ãƒ³ãƒãƒ¼ãƒˆå±¥æ­´ã¨çµ±è¨ˆã®è¡¨ç¤º"""
    try:
        # ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆè¡¨ç¤º
        import sqlite3
        conn = sqlite3.connect(data_system.db_path)
        cursor = conn.cursor()
        
        # å„ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä»¶æ•°å–å¾—
        tables_info = {
            "historical_events": "ğŸ“… ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿",
            "media_basic_info": "ğŸ“º ãƒ¡ãƒ‡ã‚£ã‚¢åŸºæœ¬æƒ…å ±", 
            "media_detailed_attributes": "ğŸ¯ ãƒ¡ãƒ‡ã‚£ã‚¢å±æ€§",
            "internal_knowledge": "ğŸ§  ç¤¾å†…çŸ¥è¦‹"
        }
        
        st.markdown("**ğŸ“Š ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ:**")
        
        cols = st.columns(len(tables_info))
        
        for i, (table, label) in enumerate(tables_info.items()):
            with cols[i]:
                try:
                    cursor.execute(f"SELECT COUNT(*) FROM {table}")
                    count = cursor.fetchone()[0]
                    st.metric(label, f"{count}ä»¶")
                except:
                    st.metric(label, "0ä»¶")
        
        conn.close()
        
        # æœ€è¿‘ã®ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
        st.markdown("---")
        st.markdown("**ğŸ“‹ æœ€è¿‘è¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿:**")
        
        # æœ€è¿‘ã®çŸ¥è¦‹è¡¨ç¤º
        conn = sqlite3.connect(data_system.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute('''
                SELECT title, category, source, created_at 
                FROM internal_knowledge 
                ORDER BY created_at DESC 
                LIMIT 5
            ''')
            
            recent_knowledge = cursor.fetchall()
            
            if recent_knowledge:
                knowledge_df = pd.DataFrame(recent_knowledge, columns=[
                    'ã‚¿ã‚¤ãƒˆãƒ«', 'ã‚«ãƒ†ã‚´ãƒª', 'ã‚½ãƒ¼ã‚¹', 'ä½œæˆæ—¥æ™‚'
                ])
                st.dataframe(knowledge_df, use_container_width=True, hide_index=True)
            else:
                st.info("ğŸ’¡ ã¾ã çŸ¥è¦‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                
        except Exception as e:
            st.warning(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        finally:
            conn.close()
            
    except Exception as e:
        st.error(f"âŒ çµ±è¨ˆè¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)}")

def show_knowledge_management(data_system):
    """çŸ¥è¦‹ç®¡ç†ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®æ”¹å–„ç‰ˆ"""
    st.markdown("#### ğŸ§  ç¤¾å†…çŸ¥è¦‹ã®ç®¡ç†")
    
    # ã‚¿ãƒ–æ§‹æˆã§æ©Ÿèƒ½ã‚’åˆ†é›¢
    tab1, tab2, tab3 = st.tabs(["â• çŸ¥è¦‹è¿½åŠ ", "ğŸ“š çŸ¥è¦‹ä¸€è¦§", "ğŸ” çŸ¥è¦‹æ¤œç´¢"])
    
    with tab1:
        # çŸ¥è¦‹è¿½åŠ ã®æ”¹å–„UI
        st.markdown("##### âœï¸ æ–°ã—ã„çŸ¥è¦‹ã‚’è¿½åŠ ")
        
        # 2åˆ—ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
        col_left, col_right = st.columns([2, 1])
        
        with col_left:
            # çŸ¥è¦‹ã®ã‚¿ã‚¤ãƒˆãƒ«
            knowledge_title = st.text_input(
                "ğŸ“ çŸ¥è¦‹ã®ã‚¿ã‚¤ãƒˆãƒ«*",
                placeholder="ä¾‹: ãƒ¡ãƒ¼ãƒ«é…ä¿¡ã®æœ€é©ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°",
                help="ã“ã®çŸ¥è¦‹ã‚’ç°¡æ½”ã«è¡¨ã™ã‚¿ã‚¤ãƒˆãƒ«ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
            )
            
            # ã‚«ãƒ†ã‚´ãƒªé¸æŠï¼ˆæ”¹å–„ç‰ˆï¼‰
            category_options = {
                "campaign": "ğŸ“¢ ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ»æ–½ç­–",
                "media": "ğŸ“º ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ»åª’ä½“",
                "audience": "ğŸ‘¥ ã‚ªãƒ¼ãƒ‡ã‚£ã‚¨ãƒ³ã‚¹ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ",
                "budget": "ğŸ’° äºˆç®—ãƒ»ã‚³ã‚¹ãƒˆ",
                "timing": "â° ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãƒ»æ™‚æœŸ",
                "general": "ğŸ“‹ ä¸€èˆ¬"
            }
            
            knowledge_category = st.selectbox(
                "ğŸ·ï¸ ã‚«ãƒ†ã‚´ãƒª*",
                options=list(category_options.keys()),
                format_func=lambda x: category_options[x],
                help="çŸ¥è¦‹ãŒæœ€ã‚‚é–¢é€£ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠã—ã¦ãã ã•ã„"
            )
            
            # çŸ¥è¦‹ã®å†…å®¹
            knowledge_content = st.text_area(
                "ğŸ“– çŸ¥è¦‹ã®è©³ç´°å†…å®¹*",
                height=120,
                placeholder="ä¾‹: ç«æ›œæ—¥ã®åˆå‰10æ™‚ã«é…ä¿¡ã™ã‚‹ã¨é–‹å°ç‡ãŒæœ€ã‚‚é«˜ã„ã€‚ç‰¹ã«BtoBå‘ã‘ã‚¤ãƒ™ãƒ³ãƒˆã§ã¯...",
                help="å…·ä½“çš„ã§å®Ÿç”¨çš„ãªå†…å®¹ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„"
            )
            
            # é©ç”¨æ¡ä»¶ï¼ˆæ”¹å–„ç‰ˆï¼‰
            st.markdown("**ğŸ¯ é©ç”¨æ¡ä»¶ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰**")
            conditions_text = st.text_area(
                "ã“ã®çŸ¥è¦‹ãŒé©ç”¨ã•ã‚Œã‚‹æ¡ä»¶ãŒã‚ã‚Œã°è¨˜è¼‰ã—ã¦ãã ã•ã„",
                height=80,
                placeholder="ä¾‹: BtoBã‚¤ãƒ™ãƒ³ãƒˆã€å‚åŠ è€…æ•°100åä»¥ä¸Šã€äºˆç®—50ä¸‡å††ä»¥ä¸Š",
                help="æ¡ä»¶ã‚’æŒ‡å®šã™ã‚‹ã¨ã€è©²å½“ã™ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆã§ã®ã¿ã“ã®çŸ¥è¦‹ãŒææ¡ˆã•ã‚Œã¾ã™"
            )
        
        with col_right:
            # çŸ¥è¦‹ã®é‡è¦åº¦è¨­å®š
            st.markdown("**âš–ï¸ çŸ¥è¦‹ã®è©•ä¾¡**")
            
            impact_score = st.slider(
                "ğŸ“Š å½±éŸ¿åº¦",
                min_value=0.0,
                max_value=1.0,
                value=0.7,
                step=0.1,
                help="ã“ã®çŸ¥è¦‹ãŒã‚¤ãƒ™ãƒ³ãƒˆæˆåŠŸã«ä¸ãˆã‚‹å½±éŸ¿ã®å¤§ãã•"
            )
            
            confidence_score = st.slider(
                "ğŸ¯ ä¿¡é ¼åº¦",
                min_value=0.0,
                max_value=1.0,
                value=0.8,
                step=0.1,
                help="ã“ã®çŸ¥è¦‹ã®ç¢ºå®Ÿæ€§ãƒ»ä¿¡é ¼æ€§"
            )
            
            # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            st.markdown("**ğŸ‘€ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼**")
            if knowledge_title and knowledge_content:
                with st.container():
                    st.markdown(f"**{knowledge_title}**")
                    st.markdown(f"ğŸ“ {category_options[knowledge_category]}")
                    st.markdown(f"ğŸ“ {knowledge_content[:100]}{'...' if len(knowledge_content) > 100 else ''}")
                    st.markdown(f"ğŸ“Š å½±éŸ¿åº¦: {impact_score} | ä¿¡é ¼åº¦: {confidence_score}")
            else:
                st.info("ğŸ’¡ ä¸Šè¨˜ãƒ•ã‚©ãƒ¼ãƒ ã‚’å…¥åŠ›ã™ã‚‹ã¨ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
        
        # çŸ¥è¦‹è¿½åŠ ãƒœã‚¿ãƒ³
        st.markdown("---")
        col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 1])
        
        with col_btn2:
            add_knowledge_btn = st.button(
                "ğŸ’¾ çŸ¥è¦‹ã‚’è¿½åŠ ",
                type="primary",
                use_container_width=True,
                disabled=not (knowledge_title and knowledge_content)
            )
        
        if add_knowledge_btn and knowledge_title and knowledge_content:
            try:
                # æ¡ä»¶ã®å‡¦ç†
                conditions = None
                if conditions_text.strip():
                    # æ¡ä»¶ã‚’ãƒªã‚¹ãƒˆå½¢å¼ã«å¤‰æ›
                    conditions_list = [c.strip() for c in conditions_text.split(',') if c.strip()]
                    conditions = {"general": conditions_list}
                
                knowledge_id = data_system.add_manual_knowledge(
                    knowledge_category, 
                    knowledge_title, 
                    knowledge_content,
                    conditions=conditions,
                    impact=impact_score
                )
                
                st.success(f"âœ… çŸ¥è¦‹ã‚’è¿½åŠ ã—ã¾ã—ãŸï¼ (ID: {knowledge_id})")
                st.balloons()  # æˆåŠŸæ™‚ã®ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
                
                # ãƒ•ã‚©ãƒ¼ãƒ ãƒªã‚»ãƒƒãƒˆ
                st.rerun()
                
            except Exception as e:
                st.error(f"âŒ çŸ¥è¦‹è¿½åŠ ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    with tab2:
        # çŸ¥è¦‹ä¸€è¦§ã®æ”¹å–„è¡¨ç¤º
        st.markdown("##### ğŸ“š ç™»éŒ²æ¸ˆã¿çŸ¥è¦‹ä¸€è¦§")
        
        try:
            import sqlite3
            conn = sqlite3.connect(data_system.db_path)
            cursor = conn.cursor()
            
            # çŸ¥è¦‹ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ï¼ˆè©³ç´°æƒ…å ±ä»˜ãï¼‰
            cursor.execute('''
                SELECT id, category, title, content, impact_score, confidence, 
                       source, created_at, conditions
                FROM internal_knowledge 
                ORDER BY impact_score DESC, created_at DESC
            ''')
            
            knowledge_data = cursor.fetchall()
            conn.close()
            
            if knowledge_data:
                # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½
                col_filter1, col_filter2, col_filter3 = st.columns(3)
                
                with col_filter1:
                    # ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                    all_categories = list(set([k[1] for k in knowledge_data]))
                    selected_categories = st.multiselect(
                        "ğŸ·ï¸ ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼",
                        all_categories,
                        default=all_categories,
                        format_func=lambda x: category_options.get(x, x)
                    )
                
                with col_filter2:
                    # ä¿¡é ¼åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                    min_confidence = st.slider(
                        "ğŸ¯ æœ€å°ä¿¡é ¼åº¦",
                        0.0, 1.0, 0.0, 0.1
                    )
                
                with col_filter3:
                    # å½±éŸ¿åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                    min_impact = st.slider(
                        "ğŸ“Š æœ€å°å½±éŸ¿åº¦",
                        0.0, 1.0, 0.0, 0.1
                    )
                
                # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é©ç”¨
                filtered_knowledge = [
                    k for k in knowledge_data 
                    if k[1] in selected_categories 
                    and k[4] >= min_impact 
                    and k[5] >= min_confidence
                ]
                
                st.markdown(f"**è¡¨ç¤ºä¸­: {len(filtered_knowledge)}ä»¶ / å…¨{len(knowledge_data)}ä»¶**")
                
                # çŸ¥è¦‹ã‚«ãƒ¼ãƒ‰è¡¨ç¤º
                for knowledge in filtered_knowledge:
                    knowledge_id, category, title, content, impact, confidence, source, created_at, conditions = knowledge
                    
                    with st.expander(f"ğŸ§  {title} [{category_options.get(category, category)}]"):
                        col_info, col_actions = st.columns([3, 1])
                        
                        with col_info:
                            st.markdown(f"**ğŸ“– å†…å®¹:** {content}")
                            
                            if conditions:
                                try:
                                    conditions_data = json.loads(conditions)
                                    if isinstance(conditions_data, dict) and 'general' in conditions_data:
                                        st.markdown(f"**ğŸ¯ é©ç”¨æ¡ä»¶:** {', '.join(conditions_data['general'])}")
                                except:
                                    pass
                            
                            st.markdown(f"**ğŸ“Š è©•ä¾¡:** å½±éŸ¿åº¦ {impact:.1f} | ä¿¡é ¼åº¦ {confidence:.1f}")
                            st.markdown(f"**ğŸ“… ä½œæˆæ—¥:** {created_at}")
                            st.markdown(f"**ğŸ“‹ ã‚½ãƒ¼ã‚¹:** {source}")
                        
                        with col_actions:
                            # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆå°†æ¥ã®æ‹¡å¼µç”¨ï¼‰
                            st.markdown("**ğŸ”§ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**")
                            if st.button(f"ğŸ“ ç·¨é›†", key=f"edit_{knowledge_id}", disabled=True):
                                st.info("ç·¨é›†æ©Ÿèƒ½ã¯ä»Šå¾Œå®Ÿè£…äºˆå®šã§ã™")
                            if st.button(f"ğŸ—‘ï¸ å‰Šé™¤", key=f"delete_{knowledge_id}", disabled=True):
                                st.info("å‰Šé™¤æ©Ÿèƒ½ã¯ä»Šå¾Œå®Ÿè£…äºˆå®šã§ã™")
            else:
                st.info("ğŸ’¡ ã¾ã çŸ¥è¦‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã€ŒçŸ¥è¦‹è¿½åŠ ã€ã‚¿ãƒ–ã‹ã‚‰è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
        
        except Exception as e:
            st.error(f"âŒ çŸ¥è¦‹è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    with tab3:
        # çŸ¥è¦‹æ¤œç´¢æ©Ÿèƒ½
        st.markdown("##### ğŸ” çŸ¥è¦‹æ¤œç´¢ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°")
        
        # æ¤œç´¢æ©Ÿèƒ½
        search_query = st.text_input(
            "ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢",
            placeholder="ä¾‹: ãƒ¡ãƒ¼ãƒ«, ã‚¿ã‚¤ãƒŸãƒ³ã‚°, BtoB",
            help="ã‚¿ã‚¤ãƒˆãƒ«ã‚„å†…å®¹ã‹ã‚‰çŸ¥è¦‹ã‚’æ¤œç´¢ã—ã¾ã™"
        )
        
        if search_query:
            try:
                import sqlite3
                conn = sqlite3.connect(data_system.db_path)
                cursor = conn.cursor()
                
                cursor.execute('''
                    SELECT id, category, title, content, impact_score, confidence, source
                    FROM internal_knowledge 
                    WHERE title LIKE ? OR content LIKE ?
                    ORDER BY impact_score DESC
                ''', (f'%{search_query}%', f'%{search_query}%'))
                
                search_results = cursor.fetchall()
                conn.close()
                
                if search_results:
                    st.success(f"ğŸ¯ {len(search_results)}ä»¶ã®çŸ¥è¦‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                    
                    for result in search_results:
                        knowledge_id, category, title, content, impact, confidence, source = result
                        
                        with st.container():
                            st.markdown(f"**ğŸ§  {title}**")
                            st.markdown(f"ğŸ“ {category_options.get(category, category)} | ğŸ“Š å½±éŸ¿åº¦: {impact:.1f} | ğŸ¯ ä¿¡é ¼åº¦: {confidence:.1f}")
                            st.markdown(f"ğŸ“– {content}")
                            st.markdown("---")
                else:
                    st.warning(f"ğŸ¤·â€â™‚ï¸ ã€Œ{search_query}ã€ã«é–¢ã™ã‚‹çŸ¥è¦‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
            except Exception as e:
                st.error(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
        else:
            st.info("ğŸ’¡ ä¸Šè¨˜ã®æ¤œç´¢ãƒœãƒƒã‚¯ã‚¹ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

def show_data_analysis(data_system):
    """ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    st.markdown("#### ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»ã‚¤ãƒ³ã‚µã‚¤ãƒˆ")
    
    # åŸºæœ¬çµ±è¨ˆ
    st.markdown("##### ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ")
    
    try:
        import sqlite3
        conn = sqlite3.connect(data_system.db_path)
        
        # ã‚¤ãƒ™ãƒ³ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
        events_df = pd.read_sql_query('''
            SELECT event_name, target_attendees, actual_attendees, budget, actual_cost,
                   campaigns_used, performance_metrics
            FROM historical_events
        ''', conn)
        
        if len(events_df) > 0:
            st.markdown("###### ğŸ¯ ã‚¤ãƒ™ãƒ³ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                avg_conversion = (events_df['actual_attendees'] / events_df['target_attendees']).mean() * 100
                st.metric("å¹³å‡é”æˆç‡", f"{avg_conversion:.1f}%")
            
            with col2:
                avg_cpa = (events_df['actual_cost'] / events_df['actual_attendees']).mean()
                st.metric("å¹³å‡CPA", f"Â¥{avg_cpa:,.0f}")
            
            with col3:
                total_events = len(events_df)
                st.metric("ç·ã‚¤ãƒ™ãƒ³ãƒˆæ•°", f"{total_events}ä»¶")
            
            # ã‚¤ãƒ™ãƒ³ãƒˆæˆæœã®å¯è¦–åŒ–
            if len(events_df) >= 3:
                fig = px.scatter(
                    events_df,
                    x='target_attendees',
                    y='actual_attendees',
                    size='budget',
                    hover_name='event_name',
                    title='ã‚¤ãƒ™ãƒ³ãƒˆç›®æ¨™ vs å®Ÿç¸¾',
                    labels={'target_attendees': 'ç›®æ¨™ç”³è¾¼æ•°', 'actual_attendees': 'å®Ÿéš›ç”³è¾¼æ•°'}
                )
                fig.add_shape(
                    type="line", line=dict(dash="dash"),
                    x0=0, y0=0, x1=events_df['target_attendees'].max(), y1=events_df['target_attendees'].max()
                )
                st.plotly_chart(fig, use_container_width=True)
        
        # ãƒ¡ãƒ‡ã‚£ã‚¢å±æ€§åˆ†æ
        media_attrs_df = pd.read_sql_query('''
            SELECT media_name, attribute_category, attribute_name, attribute_value
            FROM media_detailed_attributes
        ''', conn)
        
        if len(media_attrs_df) > 0:
            st.markdown("###### ğŸ“º ãƒ¡ãƒ‡ã‚£ã‚¢å±æ€§åˆ†æ")
            
            # å±æ€§ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®åˆ†å¸ƒ
            category_counts = media_attrs_df['attribute_category'].value_counts()
            fig = px.pie(
                values=category_counts.values,
                names=category_counts.index,
                title='ãƒ¡ãƒ‡ã‚£ã‚¢å±æ€§ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ'
            )
            st.plotly_chart(fig, use_container_width=True)
        
        conn.close()
        
    except Exception as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")

def show_data_cleaning_interface():
    """ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    st.markdown("#### ğŸ§¹ ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ»ç®¡ç†")
    
    if not INTERNAL_DATA_AVAILABLE:
        st.error("ğŸš« ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        return
    
    # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒŠãƒ¼ã®åˆæœŸåŒ–
    if 'data_cleaner' not in st.session_state:
        st.session_state['data_cleaner'] = DataCleaner()
    
    cleaner = st.session_state['data_cleaner']
    
    # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿çŠ¶æ³è¡¨ç¤º
    st.markdown("##### ğŸ“Š ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿çŠ¶æ³")
    
    try:
        import sqlite3
        conn = sqlite3.connect(cleaner.db_path)
        cursor = conn.cursor()
        
        tables = ['historical_events', 'media_performance', 'media_detailed_attributes', 'internal_knowledge']
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            cursor.execute("SELECT COUNT(*) FROM historical_events")
            events_count = cursor.fetchone()[0]
            st.metric("ğŸ“… ã‚¤ãƒ™ãƒ³ãƒˆ", f"{events_count}ä»¶")
        
        with col2:
            cursor.execute("SELECT COUNT(*) FROM media_performance")
            media_count = cursor.fetchone()[0]
            st.metric("ğŸ“º ãƒ¡ãƒ‡ã‚£ã‚¢", f"{media_count}ä»¶")
        
        with col3:
            cursor.execute("SELECT COUNT(*) FROM media_detailed_attributes")
            attrs_count = cursor.fetchone()[0]
            st.metric("ğŸ¯ å±æ€§", f"{attrs_count}ä»¶")
        
        with col4:
            cursor.execute("SELECT COUNT(*) FROM internal_knowledge")
            knowledge_count = cursor.fetchone()[0]
            st.metric("ğŸ§  çŸ¥è¦‹", f"{knowledge_count}ä»¶")
        
        # ãƒ‡ãƒ¼ã‚¿ä¾‹ã®è¡¨ç¤º
        total_records = events_count + media_count + attrs_count + knowledge_count
        
        if total_records > 0:
            st.markdown("##### ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ä¾‹")
            
            if events_count > 0:
                cursor.execute("SELECT event_name FROM historical_events LIMIT 3")
                event_samples = [row[0] for row in cursor.fetchall()]
                st.write(f"**ã‚¤ãƒ™ãƒ³ãƒˆä¾‹**: {', '.join(event_samples)}")
            
            if media_count > 0:
                cursor.execute("SELECT media_name FROM media_performance LIMIT 3")
                media_samples = [row[0] for row in cursor.fetchall()]
                st.write(f"**ãƒ¡ãƒ‡ã‚£ã‚¢ä¾‹**: {', '.join(media_samples)}")
        
        conn.close()
        
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿çŠ¶æ³ç¢ºèªã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    st.markdown("---")
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿æ¤œå‡º
    st.markdown("##### ğŸ” ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿æ¤œå‡º")
    
    if st.button("ğŸ” ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ãƒã‚§ãƒƒã‚¯", use_container_width=True):
        with st.spinner("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œå‡ºä¸­..."):
            try:
                sample_data = cleaner.check_sample_data()
                total_samples = sum(len(items) for items in sample_data.values())
                
                if total_samples == 0:
                    st.success("âœ… ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                else:
                    st.warning(f"âš ï¸ {total_samples}ä»¶ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
                    
                    for table, items in sample_data.items():
                        if items:
                            with st.expander(f"ğŸ“‹ {table} ({len(items)}ä»¶)"):
                                for item in items:
                                    if table == "historical_events":
                                        st.write(f"- **{item['name']}** (ID: {item['id']}) - {item['reason']}")
                                    elif table == "media_performance":
                                        st.write(f"- **{item['name']}** (ID: {item['id']}) - {item['reason']}")
                                    elif table == "internal_knowledge":
                                        st.write(f"- **{item['title']}** (ID: {item['id']}) - {item['reason']}")
                    
                    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ãƒœã‚¿ãƒ³
                    st.markdown("##### ğŸ—‘ï¸ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿å‰Šé™¤")
                    
                    col_clean1, col_clean2 = st.columns(2)
                    
                    with col_clean1:
                        if st.button("ğŸ§¹ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ã¿å‰Šé™¤", type="secondary", use_container_width=True):
                            with st.spinner("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ä¸­..."):
                                try:
                                    removed = cleaner.remove_sample_data(sample_data)
                                    st.success(f"âœ… ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {removed}")
                                    st.rerun()
                                except Exception as e:
                                    st.error(f"âŒ å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    
                    with col_clean2:
                        if st.button("ğŸ”„ å…¨ãƒ‡ãƒ¼ã‚¿ãƒªã‚»ãƒƒãƒˆ", type="primary", use_container_width=True):
                            if st.checkbox("âš ï¸ å…¨ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ã‚’ç¢ºèª"):
                                with st.spinner("å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆä¸­..."):
                                    try:
                                        backup_path = cleaner.reset_all_data()
                                        st.success(f"âœ… å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
                                        st.info(f"ğŸ“¦ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_path}")
                                        st.rerun()
                                    except Exception as e:
                                        st.error(f"âŒ ãƒªã‚»ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
                            else:
                                st.warning("âš ï¸ ç¢ºèªãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã«ãƒã‚§ãƒƒã‚¯ã‚’å…¥ã‚Œã¦ãã ã•ã„")
                    
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                    st.session_state['detected_sample_data'] = sample_data
                
            except Exception as e:
                st.error(f"âŒ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç®¡ç†
    st.markdown("---")
    st.markdown("##### ğŸ“¦ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç®¡ç†")
    
    col_backup1, col_backup2 = st.columns(2)
    
    with col_backup1:
        if st.button("ğŸ“¦ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ", use_container_width=True):
            try:
                backup_path = cleaner.create_backup()
                st.success(f"âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆã—ã¾ã—ãŸ")
                st.info(f"ğŸ“ å ´æ‰€: {backup_path}")
            except Exception as e:
                st.error(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    with col_backup2:
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸€è¦§ã‚’è¡¨ç¤ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
        try:
            backup_dir = Path("data/backups")
            if backup_dir.exists():
                backups = list(backup_dir.glob("*.db"))
                if backups:
                    st.info(f"ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {len(backups)}å€‹")
                else:
                    st.info("ğŸ“‹ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯ã‚ã‚Šã¾ã›ã‚“")
            else:
                st.info("ğŸ“‹ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒã‚ã‚Šã¾ã›ã‚“")
        except Exception as e:
            st.warning(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç¢ºèªã‚¨ãƒ©ãƒ¼: {str(e)}")

def show_supabase_data_management():
    """Supabaseç”¨ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‡ãƒ¼ã‚¿ç®¡ç†ç”»é¢"""
    shared_db = st.session_state.get('shared_db')
    
    if not shared_db:
        st.error("âŒ Supabaseãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # ã‚¿ãƒ–æ§‹æˆ
    overview_tab, add_event_tab, view_data_tab = st.tabs(["ğŸ“Š æ¦‚è¦", "â• ã‚¤ãƒ™ãƒ³ãƒˆè¿½åŠ ", "ğŸ‘€ ãƒ‡ãƒ¼ã‚¿ç¢ºèª"])
    
    with overview_tab:
        st.markdown("### ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¦‚è¦")
        
        # ç°¡å˜ãªçµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
        try:
            events = shared_db.get_all_events()
            st.metric("ğŸ“… ç™»éŒ²æ¸ˆã¿ã‚¤ãƒ™ãƒ³ãƒˆæ•°", f"{len(events)}ä»¶")
            
            if events:
                st.markdown("#### ğŸ“‹ æœ€è¿‘ã®ã‚¤ãƒ™ãƒ³ãƒˆ")
                recent_events = events[:5]  # æœ€æ–°5ä»¶
                for event in recent_events:
                    st.markdown(f"- **{event['event_name']}** ({event['category']}) - {event['created_at']}")
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    with add_event_tab:
        st.markdown("### â• æ–°ã—ã„ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ")
        
        with st.form("add_event_form"):
            event_name = st.text_input("ğŸ“ ã‚¤ãƒ™ãƒ³ãƒˆå*", placeholder="ä¾‹: AIæŠ€è¡“ã‚»ãƒŸãƒŠãƒ¼2025")
            theme = st.text_area("ğŸ¯ ãƒ†ãƒ¼ãƒãƒ»å†…å®¹*", placeholder="ä¾‹: æœ€æ–°ã®AIæŠ€è¡“å‹•å‘ã¨å®Ÿè·µäº‹ä¾‹")
            
            col1, col2 = st.columns(2)
            with col1:
                category = st.selectbox("ğŸ“‹ ã‚«ãƒ†ã‚´ãƒª", 
                    ["conference", "seminar", "workshop", "webinar", "networking"],
                    format_func=lambda x: {"conference": "ã‚«ãƒ³ãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹", "seminar": "ã‚»ãƒŸãƒŠãƒ¼", 
                                          "workshop": "ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—", "webinar": "ã‚¦ã‚§ãƒ“ãƒŠãƒ¼", 
                                          "networking": "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚­ãƒ³ã‚°"}[x])
                target_attendees = st.number_input("ğŸ¯ ç›®æ¨™å‚åŠ è€…æ•°", min_value=1, value=100)
                budget = st.number_input("ğŸ’° äºˆç®—ï¼ˆå††ï¼‰", min_value=0, value=500000, step=50000)
            
            with col2:
                actual_attendees = st.number_input("âœ… å®Ÿéš›ã®å‚åŠ è€…æ•°", min_value=0, value=0)
                actual_cost = st.number_input("ğŸ’¸ å®Ÿéš›ã®ã‚³ã‚¹ãƒˆï¼ˆå††ï¼‰", min_value=0, value=0, step=10000)
                event_date = st.date_input("ğŸ“… é–‹å‚¬æ—¥", value=datetime.now().date())
            
            submitted = st.form_submit_button("ğŸ’¾ ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜", type="primary")
            
            if submitted:
                if event_name and theme:
                    try:
                        event_data = {
                            'event_name': event_name,
                            'theme': theme,
                            'category': category,
                            'target_attendees': target_attendees,
                            'actual_attendees': actual_attendees,
                            'budget': budget,
                            'actual_cost': actual_cost,
                            'event_date': event_date,
                            'campaigns_used': [],
                            'performance_metrics': {}
                        }
                        
                        if shared_db.insert_event_data(event_data, "streamlit_user"):
                            st.success("âœ… ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
                            st.balloons()
                        else:
                            st.error("âŒ ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    except Exception as e:
                        st.error(f"âŒ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
                else:
                    st.error("âŒ ã‚¤ãƒ™ãƒ³ãƒˆåã¨ãƒ†ãƒ¼ãƒã¯å¿…é ˆã§ã™")
    
    with view_data_tab:
        st.markdown("### ğŸ‘€ ç™»éŒ²æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿")
        
        try:
            events = shared_db.get_all_events()
            
            if events:
                # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›ã—ã¦è¡¨ç¤º
                import pandas as pd
                df = pd.DataFrame(events)
                
                # åˆ—åã‚’æ—¥æœ¬èªã«å¤‰æ›
                column_mapping = {
                    'event_name': 'ã‚¤ãƒ™ãƒ³ãƒˆå',
                    'category': 'ã‚«ãƒ†ã‚´ãƒª',
                    'target_attendees': 'ç›®æ¨™å‚åŠ è€…',
                    'actual_attendees': 'å®Ÿéš›å‚åŠ è€…',
                    'budget': 'äºˆç®—',
                    'actual_cost': 'å®Ÿéš›ã‚³ã‚¹ãƒˆ',
                    'event_date': 'é–‹å‚¬æ—¥',
                    'created_at': 'ç™»éŒ²æ—¥'
                }
                
                # è¡¨ç¤ºç”¨ã«åˆ—ã‚’é¸æŠãƒ»ãƒªãƒãƒ¼ãƒ 
                display_columns = ['event_name', 'category', 'target_attendees', 'actual_attendees', 
                                 'budget', 'actual_cost', 'event_date', 'created_at']
                df_display = df[display_columns].rename(columns=column_mapping)
                
                st.dataframe(df_display, use_container_width=True)
                
                # ç°¡å˜ãªåˆ†æ
                if len(events) > 1:
                    st.markdown("#### ğŸ“Š ç°¡å˜ãªåˆ†æ")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        avg_conversion = (df['actual_attendees'] / df['target_attendees']).mean() * 100
                        st.metric("å¹³å‡é”æˆç‡", f"{avg_conversion:.1f}%")
                    
                    with col2:
                        total_budget = df['budget'].sum()
                        st.metric("ç·äºˆç®—", f"Â¥{total_budget:,}")
                    
                    with col3:
                        total_participants = df['actual_attendees'].sum()
                        st.metric("ç·å‚åŠ è€…æ•°", f"{total_participants:,}äºº")
            else:
                st.info("ğŸ“ ã¾ã ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã€Œã‚¤ãƒ™ãƒ³ãƒˆè¿½åŠ ã€ã‚¿ãƒ–ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
                
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)}")

def show_basic_data_management():
    """åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿ç®¡ç†ç”»é¢ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
    st.markdown("### ğŸ”§ åŸºæœ¬ãƒ¢ãƒ¼ãƒ‰")
    st.info("ğŸ’¡ ç¾åœ¨ã€åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿ç®¡ç†æ©Ÿèƒ½ã®ã¿åˆ©ç”¨å¯èƒ½ã§ã™ã€‚")
    
    st.markdown("#### ğŸ“ æ‰‹å‹•ãƒ‡ãƒ¼ã‚¿å…¥åŠ›")
    
    with st.form("basic_data_form"):
        st.markdown("**ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±**")
        event_name = st.text_input("ã‚¤ãƒ™ãƒ³ãƒˆå")
        event_description = st.text_area("ã‚¤ãƒ™ãƒ³ãƒˆèª¬æ˜")
        
        col1, col2 = st.columns(2)
        with col1:
            target_num = st.number_input("ç›®æ¨™å‚åŠ è€…æ•°", min_value=0, value=100)
        with col2:
            budget = st.number_input("äºˆç®—ï¼ˆå††ï¼‰", min_value=0, value=500000)
        
        submitted = st.form_submit_button("ğŸ’¾ ä¿å­˜")
        
        if submitted:
            if event_name:
                st.success(f"âœ… ã‚¤ãƒ™ãƒ³ãƒˆã€Œ{event_name}ã€ã®æƒ…å ±ã‚’è¨˜éŒ²ã—ã¾ã—ãŸ")
                st.info("ğŸ’¡ ã“ã®æƒ…å ±ã¯ä¸€æ™‚çš„ãªã‚‚ã®ã§ã™ã€‚å®Œå…¨ãªæ©Ÿèƒ½ã‚’åˆ©ç”¨ã™ã‚‹ã«ã¯ã€é©åˆ‡ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒå¿…è¦ã§ã™ã€‚")
            else:
                st.error("âŒ ã‚¤ãƒ™ãƒ³ãƒˆåã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
    st.markdown("---")
    st.markdown("##### âœ… ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯")
    
    if st.button("ğŸ”¬ ãƒ‡ãƒ¼ã‚¿å“è³ªã‚’åˆ†æ", use_container_width=True):
        with st.spinner("ãƒ‡ãƒ¼ã‚¿å“è³ªã‚’åˆ†æä¸­..."):
            try:
                # ç°¡æ˜“çš„ãªå“è³ªãƒã‚§ãƒƒã‚¯
                conn = sqlite3.connect(cleaner.db_path)
                cursor = conn.cursor()
                
                issues = []
                
                # ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã®å“è³ªãƒã‚§ãƒƒã‚¯
                cursor.execute("SELECT COUNT(*) FROM historical_events WHERE event_name IS NULL OR event_name = ''")
                empty_names = cursor.fetchone()[0]
                if empty_names > 0:
                    issues.append(f"ã‚¤ãƒ™ãƒ³ãƒˆåæœªè¨­å®š: {empty_names}ä»¶")
                
                cursor.execute("SELECT COUNT(*) FROM historical_events WHERE target_attendees <= 0")
                invalid_targets = cursor.fetchone()[0]
                if invalid_targets > 0:
                    issues.append(f"ç„¡åŠ¹ãªç›®æ¨™å‚åŠ è€…æ•°: {invalid_targets}ä»¶")
                
                cursor.execute("SELECT COUNT(*) FROM historical_events WHERE actual_attendees > target_attendees * 3")
                unrealistic_results = cursor.fetchone()[0]
                if unrealistic_results > 0:
                    issues.append(f"éç¾å®Ÿçš„ãªå®Ÿç¸¾å€¤: {unrealistic_results}ä»¶")
                
                conn.close()
                
                if issues:
                    st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿å“è³ªã®å•é¡Œã‚’æ¤œå‡ºã—ã¾ã—ãŸ:")
                    for issue in issues:
                        st.write(f"- {issue}")
                else:
                    st.success("âœ… ãƒ‡ãƒ¼ã‚¿å“è³ªã«å•é¡Œã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                
            except Exception as e:
                st.error(f"âŒ å“è³ªãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {str(e)}")

def show_detailed_data_report(data_system):
    """è©³ç´°ãƒ‡ãƒ¼ã‚¿ãƒ¬ãƒãƒ¼ãƒˆã®è¡¨ç¤º"""
    st.markdown("### ğŸ“‹ è©³ç´°ãƒ‡ãƒ¼ã‚¿ãƒ¬ãƒãƒ¼ãƒˆ")
    
    try:
        # ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ã®è©³ç´°è¡¨ç¤ºã‚’ã“ã“ã«å®Ÿè£…
        data_system.show_data_overview()
        st.success("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ¬ãƒãƒ¼ãƒˆã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›ã—ã¾ã—ãŸ")
    except Exception as e:
        st.error(f"âŒ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")

def show_welcome_screen():
    """ã‚¦ã‚§ãƒ«ã‚«ãƒ ç”»é¢ã®è¡¨ç¤º"""
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        st.markdown("""
        ### ğŸ¯ ã‚¤ãƒ™ãƒ³ãƒˆé›†å®¢æ–½ç­–ææ¡ˆAIã¸ã‚ˆã†ã“ã
        
        ã“ã®ãƒ„ãƒ¼ãƒ«ã¯ã€ã‚¤ãƒ™ãƒ³ãƒˆã®è©³ç´°æƒ…å ±ã«åŸºã¥ã„ã¦æœ€é©ãªé›†å®¢æ–½ç­–ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’ææ¡ˆã—ã¾ã™ã€‚
        
        #### ğŸ“‹ æ©Ÿèƒ½
        - **ç„¡æ–™ãƒ»æœ‰æ–™æ–½ç­–ã®æœ€é©çµ„ã¿åˆã‚ã›ææ¡ˆ**
        - **äºˆç®—é…åˆ†ã®æœ€é©åŒ–**
        - **æˆæœäºˆæ¸¬ã¨ãƒªã‚¹ã‚¯åˆ†æ**
        - **å®Ÿè£…ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã®æä¾›**
        
        #### ğŸš€ ä½¿ã„æ–¹
        1. å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ã‚’å…¥åŠ›
        2. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚ªãƒ¼ãƒ‡ã‚£ã‚¨ãƒ³ã‚¹ã‚’è¨­å®š
        3. ç›®æ¨™ç”³è¾¼äººæ•°ã¨äºˆç®—ã‚’å…¥åŠ›
        4. ã€Œæ–½ç­–ææ¡ˆã‚’ç”Ÿæˆã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
        
        ã¾ãšã¯å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰æƒ…å ±ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼
        """)

def generate_recommendations(event_name, event_category, event_theme, industries, 
                           job_titles, company_sizes, target_attendees, budget, 
                           event_date, is_free_event, event_format, use_ai_engine=False):
    """æ–½ç­–ææ¡ˆã®ç”Ÿæˆ"""
    
    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    request_data = {
        "event_name": event_name,
        "event_category": event_category,
        "event_theme": event_theme,
        "target_audience": {
            "job_titles": job_titles,
            "industries": industries,
            "company_sizes": company_sizes
        },
        "target_attendees": target_attendees,
        "budget": budget,
        "event_date": event_date.isoformat(),
        "is_free_event": is_free_event,
        "event_format": event_format,
        "priority_metrics": ["conversions", "cost_efficiency"]
    }
    
    with st.spinner("ğŸ¤– AIãŒæœ€é©ãªæ–½ç­–ã‚’åˆ†æä¸­..."):
        try:
            if use_ai_engine:
                # é«˜åº¦AIäºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½¿ç”¨
                response = use_ai_prediction_engine(request_data)
            else:
                # ãƒ¢ãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
                response = create_mock_response(request_data)
            
            st.session_state.recommendations = response
            st.success("âœ… æ–½ç­–ææ¡ˆãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸï¼")
            st.rerun()
            
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

def use_ai_prediction_engine(request_data):
    """å®Ÿéš›ã®AIäºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½¿ç”¨"""
    import asyncio
    
    try:
        from services.data_manager import DataManager
        from services.campaign_optimizer import CampaignOptimizer
        from services.prediction_engine import PredictionEngine
        from models.event_model import EventRequest, TargetAudience, EventCategory, EventFormat
    except ImportError as e:
        st.error(f"AIäºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {str(e)}")
        return create_mock_response(request_data)
    
    try:
        # EventRequestã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä½œæˆ
        target_audience = TargetAudience(
            job_titles=request_data["target_audience"]["job_titles"],
            industries=request_data["target_audience"]["industries"],
            company_sizes=request_data["target_audience"]["company_sizes"]
        )
        
        event_request = EventRequest(
            event_name=request_data["event_name"],
            event_category=EventCategory(request_data["event_category"]),
            event_theme=request_data["event_theme"],
            target_audience=target_audience,
            target_attendees=request_data["target_attendees"],
            budget=request_data["budget"],
            event_date=datetime.fromisoformat(request_data["event_date"]),
            is_free_event=request_data["is_free_event"],
            event_format=EventFormat(request_data["event_format"])
        )
        
        # AI ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–ã¨å®Ÿè¡Œ
        async def run_ai_analysis():
            data_manager = DataManager()
            await data_manager.initialize()
            
            optimizer = CampaignOptimizer(data_manager)
            prediction_engine = PredictionEngine(data_manager)
            
            # æ–½ç­–æœ€é©åŒ–
            campaigns = await optimizer.optimize_portfolio(event_request)
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬
            performance = await prediction_engine.predict_performance(event_request, campaigns)
            
            return campaigns, performance
        
        campaigns, performance = asyncio.run(run_ai_analysis())
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã«å¤‰æ›
        response = {
            "event_info": request_data,
            "recommended_campaigns": [
                {
                    "channel": campaign.channel.value,
                    "campaign_name": campaign.campaign_name,
                    "description": campaign.description,
                    "is_paid": campaign.is_paid,
                    "estimated_cost": campaign.estimated_cost,
                    "estimated_reach": campaign.estimated_reach,
                    "estimated_conversions": campaign.estimated_conversions,
                    "estimated_ctr": campaign.estimated_ctr,
                    "estimated_cvr": campaign.estimated_cvr,
                    "estimated_cpa": campaign.estimated_cpa,
                    "confidence_score": campaign.confidence_score,
                    "implementation_timeline": campaign.implementation_timeline,
                    "required_resources": campaign.required_resources
                }
                for campaign in campaigns
            ],
            "performance_predictions": {
                "total_reach": performance.total_reach,
                "total_conversions": performance.total_conversions,
                "total_cost": performance.total_cost,
                "overall_ctr": performance.overall_ctr,
                "overall_cvr": performance.overall_cvr,
                "overall_cpa": performance.overall_cpa,
                "goal_achievement_probability": performance.goal_achievement_probability,
                "risk_factors": performance.risk_factors,
                "optimization_suggestions": performance.optimization_suggestions
            },
            "total_estimated_cost": performance.total_cost,
            "total_estimated_reach": performance.total_reach,
            "total_estimated_conversions": performance.total_conversions,
            "budget_allocation": {
                "ç„¡æ–™æ–½ç­–": sum(c.estimated_cost for c in campaigns if not c.is_paid) / performance.total_cost if performance.total_cost > 0 else 0,
                "æœ‰æ–™æ–½ç­–": sum(c.estimated_cost for c in campaigns if c.is_paid) / performance.total_cost if performance.total_cost > 0 else 1
            }
        }
        
        st.info("ğŸ§  é«˜åº¦AIäºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³ã«ã‚ˆã‚‹åˆ†æçµæœã‚’è¡¨ç¤ºä¸­...")
        return response
    
    except Exception as e:
        st.error(f"AIäºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}")
        st.info("ğŸ’¡ ãƒ¢ãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸ")
        return create_mock_response(request_data)

def create_mock_response(request_data):
    """ç¤¾å†…ãƒ‡ãƒ¼ã‚¿æ´»ç”¨å‹æ–½ç­–ææ¡ˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
    try:
        # ç¤¾å†…ãƒ‡ãƒ¼ã‚¿ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
        from internal_data_system import InternalDataSystem
        data_system = InternalDataSystem()
        
        # ã‚¤ãƒ™ãƒ³ãƒˆæ¡ä»¶ã®æº–å‚™
        event_conditions = {
            "target_audience": request_data.get("target_audience", {}),
            "budget": request_data.get("budget", 0),
            "attendees": request_data.get("target_attendees", 0),
            "category": request_data.get("event_category", ""),
            "format": request_data.get("event_format", ""),
            "is_free": request_data.get("is_free_event", True)
        }
        
        # ç¤¾å†…çŸ¥è¦‹ã®å–å¾—
        applicable_knowledge = data_system.get_applicable_knowledge(event_conditions)
        
        # åŸºæœ¬æ–½ç­–ã®ç”Ÿæˆï¼ˆçŸ¥è¦‹ã‚’æ´»ç”¨ï¼‰
        campaigns = generate_knowledge_enhanced_campaigns(request_data, applicable_knowledge)
        
        # çŸ¥è¦‹ãƒ™ãƒ¼ã‚¹ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬
        performance = calculate_enhanced_performance(campaigns, applicable_knowledge)
        
        # çŸ¥è¦‹ãƒ™ãƒ¼ã‚¹ã®ææ¡ˆã¨ãƒªã‚¹ã‚¯è©•ä¾¡
        suggestions = generate_smart_suggestions(applicable_knowledge, request_data)
        risks = assess_smart_risks(applicable_knowledge, request_data, campaigns)
        
        # ç·è¨ˆã®è¨ˆç®—
        total_cost = sum(c['estimated_cost'] for c in campaigns)
        total_reach = sum(c['estimated_reach'] for c in campaigns)
        total_conversions = sum(c['estimated_conversions'] for c in campaigns)
        
        # äºˆç®—é…åˆ†
        free_cost = sum(c['estimated_cost'] for c in campaigns if not c['is_paid'])
        paid_cost = sum(c['estimated_cost'] for c in campaigns if c['is_paid'])
        
        return {
            "event_info": request_data,
            "recommended_campaigns": campaigns,
            "performance_predictions": {
                "total_reach": total_reach,
                "total_conversions": total_conversions,
                "total_cost": total_cost,
                "overall_ctr": performance.get("ctr", 2.5),
                "overall_cvr": performance.get("cvr", 4.0),
                "overall_cpa": total_cost / total_conversions if total_conversions > 0 else 0,
                "goal_achievement_probability": performance.get("goal_probability", 0.75),
                "risk_factors": risks,
                "optimization_suggestions": suggestions
            },
            "total_estimated_cost": total_cost,
            "total_estimated_reach": total_reach,
            "total_estimated_conversions": total_conversions,
            "budget_allocation": {
                "ç„¡æ–™æ–½ç­–": free_cost / total_cost if total_cost > 0 else 1.0,
                "æœ‰æ–™æ–½ç­–": paid_cost / total_cost if total_cost > 0 else 0.0
            },
            "applied_knowledge_count": len(applicable_knowledge),
            "analysis_method": "knowledge_enhanced"
        }
        
    except Exception as e:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªãƒ¢ãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹
        return create_basic_fallback_response(request_data)

def generate_knowledge_enhanced_campaigns(request_data, knowledge_list):
    """çŸ¥è¦‹ã‚’æ´»ç”¨ã—ãŸæ–½ç­–ç”Ÿæˆ"""
    budget = request_data.get("budget", 0)
    target_attendees = request_data.get("target_attendees", 100)
    
    # åŸºæœ¬æ–½ç­–ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
    base_campaigns = [
        {
            "channel": "email_marketing",
            "campaign_name": "ãƒ¡ãƒ¼ãƒ«ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°",
            "description": "æ—¢å­˜ãƒªã‚¹ãƒˆã¸ã®ãƒ¡ãƒ¼ãƒ«é…ä¿¡",
            "is_paid": False,
            "base_cost": 0,
            "base_reach": 5000,
            "base_conversions": 50,
            "base_ctr": 2.0,
            "base_cvr": 5.0
        },
        {
            "channel": "social_media",
            "campaign_name": "SNSæœ‰æ©ŸæŠ•ç¨¿",
            "description": "SNSã§ã®æœ‰æ©ŸæŠ•ç¨¿ã«ã‚ˆã‚‹é›†å®¢",
            "is_paid": False,
            "base_cost": 0,
            "base_reach": 3000,
            "base_conversions": 25,
            "base_ctr": 1.5,
            "base_cvr": 3.0
        }
    ]
    
    # äºˆç®—ãŒã‚ã‚‹å ´åˆã¯æœ‰æ–™æ–½ç­–ã‚’è¿½åŠ 
    if budget > 50000:
        base_campaigns.append({
            "channel": "paid_advertising",
            "campaign_name": "ãƒ‡ã‚¸ã‚¿ãƒ«åºƒå‘Š",
            "description": "Google/Metaåºƒå‘Šã«ã‚ˆã‚‹é›†å®¢",
            "is_paid": True,
            "base_cost": min(budget * 0.6, 300000),
            "base_reach": 8000,
            "base_conversions": 40,
            "base_ctr": 3.0,
            "base_cvr": 2.5
        })
    
    # çŸ¥è¦‹ã‚’å„æ–½ç­–ã«é©ç”¨
    enhanced_campaigns = []
    for campaign in base_campaigns:
        enhanced = apply_knowledge_boost(campaign, knowledge_list)
        enhanced_campaigns.append(enhanced)
    
    return enhanced_campaigns

def apply_knowledge_boost(campaign, knowledge_list):
    """çŸ¥è¦‹ã«ã‚ˆã‚‹æ–½ç­–å¼·åŒ–"""
    boost_factor = 1.0
    confidence_boost = 0.6
    applied_knowledge = []
    
    # é–¢é€£ã™ã‚‹çŸ¥è¦‹ã‚’æ¢ã™
    channel_keywords = {
        'email_marketing': ['ãƒ¡ãƒ¼ãƒ«', 'email'],
        'social_media': ['sns', 'social', 'twitter'],
        'paid_advertising': ['åºƒå‘Š', 'paid', 'ad']
    }
    
    keywords = channel_keywords.get(campaign['channel'], [])
    
    for knowledge in knowledge_list:
        content = knowledge.get('content', '').lower()
        if any(keyword in content for keyword in keywords):
            impact = knowledge.get('impact_score', 0.7)
            confidence = knowledge.get('confidence', 0.8)
            
            boost_factor *= (1 + impact * 0.15)  # æœ€å¤§15%å‘ä¸Š
            confidence_boost += confidence * 0.1
            applied_knowledge.append(knowledge.get('title', 'Unknown'))
    
    # å¼·åŒ–ã•ã‚ŒãŸæ–½ç­–ã‚’è¿”ã™
    return {
        'channel': campaign['channel'],
        'campaign_name': campaign['campaign_name'],
        'description': campaign['description'] + (f" (çŸ¥è¦‹{len(applied_knowledge)}ä»¶é©ç”¨)" if applied_knowledge else ""),
        'is_paid': campaign['is_paid'],
        'estimated_cost': int(campaign['base_cost']),
        'estimated_reach': int(campaign['base_reach'] * boost_factor),
        'estimated_conversions': int(campaign['base_conversions'] * boost_factor),
        'estimated_ctr': campaign['base_ctr'] * boost_factor,
        'estimated_cvr': campaign['base_cvr'] * boost_factor,
        'estimated_cpa': campaign['base_cost'] / max(1, campaign['base_conversions'] * boost_factor),
        'confidence_score': min(0.95, confidence_boost),
        'implementation_timeline': "çŸ¥è¦‹æœ€é©åŒ–æ¸ˆã¿ã‚¿ã‚¤ãƒŸãƒ³ã‚°",
        'required_resources': ["åŸºæœ¬ãƒªã‚½ãƒ¼ã‚¹", "çŸ¥è¦‹é©ç”¨"],
        'applied_knowledge': applied_knowledge
    }

def calculate_enhanced_performance(campaigns, knowledge_list):
    """çŸ¥è¦‹å¼·åŒ–ã•ã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆç®—"""
    knowledge_boost = len(knowledge_list) * 0.05  # çŸ¥è¦‹1ä»¶ã«ã¤ã5%å‘ä¸Š
    
    return {
        "ctr": 2.5 * (1 + knowledge_boost),
        "cvr": 4.0 * (1 + knowledge_boost),
        "goal_probability": min(0.9, 0.7 + knowledge_boost)
    }

def generate_smart_suggestions(knowledge_list, request_data):
    """ã‚¹ãƒãƒ¼ãƒˆãªææ¡ˆã®ç”Ÿæˆ"""
    suggestions = []
    
    if len(knowledge_list) > 0:
        suggestions.append(f"ğŸ§  {len(knowledge_list)}ä»¶ã®ç¤¾å†…çŸ¥è¦‹ãŒæ–½ç­–ã«é©ç”¨ã•ã‚Œã¦ã„ã¾ã™")
    else:
        suggestions.append("ğŸ’¡ ç¤¾å†…çŸ¥è¦‹ã‚’è“„ç©ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šç²¾å¯†ãªæ–½ç­–ææ¡ˆãŒå¯èƒ½ã«ãªã‚Šã¾ã™")
    
    budget = request_data.get("budget", 0)
    if budget > 0:
        suggestions.append("ğŸ’° äºˆç®—ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€æœ‰æ–™æ–½ç­–ã¨ã®çµ„ã¿åˆã‚ã›ãŒæœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™")
    else:
        suggestions.append("ğŸ’¡ ç„¡æ–™æ–½ç­–ä¸­å¿ƒã®æ§‹æˆã§ã™ã€‚å°‘é¡ã§ã‚‚äºˆç®—è¨­å®šã™ã‚‹ã¨é¸æŠè‚¢ãŒåºƒãŒã‚Šã¾ã™")
    
    return suggestions

def assess_smart_risks(knowledge_list, request_data, campaigns):
    """ã‚¹ãƒãƒ¼ãƒˆãªãƒªã‚¹ã‚¯è©•ä¾¡"""
    risks = []
    
    if len(knowledge_list) == 0:
        risks.append("ğŸ“š ç¤¾å†…çŸ¥è¦‹ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€æ±ç”¨çš„ãªææ¡ˆã¨ãªã£ã¦ã„ã¾ã™")
    
    low_confidence_knowledge = [k for k in knowledge_list if k.get('confidence', 1.0) < 0.6]
    if low_confidence_knowledge:
        risks.append("âš ï¸ ä¿¡é ¼åº¦ã®ä½ã„çŸ¥è¦‹ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
    
    if not risks:
        risks.append("âœ… å¤§ããªãƒªã‚¹ã‚¯è¦å› ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
    
    return risks

def create_basic_fallback_response(request_data):
    """åŸºæœ¬ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    return {
        "event_info": request_data,
        "recommended_campaigns": [
            {
                "channel": "email_marketing",
                "campaign_name": "åŸºæœ¬ãƒ¡ãƒ¼ãƒ«é…ä¿¡",
                "description": "æ—¢å­˜ãƒªã‚¹ãƒˆã¸ã®ãƒ¡ãƒ¼ãƒ«é…ä¿¡",
                "is_paid": False,
                "estimated_cost": 0,
                "estimated_reach": 3000,
                "estimated_conversions": 30,
                "estimated_ctr": 2.0,
                "estimated_cvr": 4.0,
                "estimated_cpa": 0,
                "confidence_score": 0.6,
                "implementation_timeline": "2é€±é–“å‰é–‹å§‹",
                "required_resources": ["ãƒ¡ãƒ¼ãƒ«é…ä¿¡ãƒ„ãƒ¼ãƒ«"]
            }
        ],
        "performance_predictions": {
            "total_reach": 3000,
            "total_conversions": 30,
            "total_cost": 0,
            "overall_ctr": 2.0,
            "overall_cvr": 4.0,
            "overall_cpa": 0,
            "goal_achievement_probability": 0.6,
            "risk_factors": ["åŸºæœ¬çš„ãªææ¡ˆã®ã¿ã§ã™"],
            "optimization_suggestions": ["ç¤¾å†…ãƒ‡ãƒ¼ã‚¿ã‚’è“„ç©ã—ã¦ãã ã•ã„"]
        },
        "total_estimated_cost": 0,
        "total_estimated_reach": 3000,
        "total_estimated_conversions": 30,
        "budget_allocation": {"ç„¡æ–™æ–½ç­–": 1.0, "æœ‰æ–™æ–½ç­–": 0.0}
    }

def show_recommendations():
    """æ–½ç­–ææ¡ˆã®è¡¨ç¤º"""
    try:
        data = st.session_state.recommendations
        
        # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        st.markdown('<h2 class="sub-header">ğŸ“Š äºˆæ¸¬ã‚µãƒãƒªãƒ¼</h2>', unsafe_allow_html=True)
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            target_percentage = ""
            try:
                target_attendees = data['event_info'].get('target_attendees', 0)
                total_conversions = data.get('total_estimated_conversions', 0)
                
                if target_attendees and target_attendees > 0 and total_conversions >= 0:
                    percentage = (total_conversions / target_attendees) * 100
                    target_percentage = f"ç›®æ¨™ã®{percentage:.1f}%"
                elif target_attendees == 0:
                    target_percentage = "ç›®æ¨™æœªè¨­å®š"
                else:
                    target_percentage = "ç›®æ¨™æƒ…å ±ãªã—"
            except (ZeroDivisionError, TypeError, KeyError):
                target_percentage = "è¨ˆç®—ã‚¨ãƒ©ãƒ¼"
            
            st.metric(
                "äºˆæ¸¬ç”³è¾¼äººæ•°",
                f"{data['total_estimated_conversions']}äºº",
                target_percentage
            )
        
        with col2:
            st.metric(
                "ç·ãƒªãƒ¼ãƒæ•°",
                f"{data['total_estimated_reach']:,}äºº"
            )
        
        with col3:
            budget_percentage = ""
            try:
                budget = data['event_info'].get('budget', 0)
                total_cost = data.get('total_estimated_cost', 0)
                
                if budget and budget > 0 and total_cost >= 0:
                    percentage = (total_cost / budget) * 100
                    budget_percentage = f"äºˆç®—ã®{percentage:.1f}%"
                elif budget == 0:
                    budget_percentage = "äºˆç®—æœªè¨­å®š"
                else:
                    budget_percentage = "äºˆç®—æƒ…å ±ãªã—"
            except (ZeroDivisionError, TypeError, KeyError):
                budget_percentage = "è¨ˆç®—ã‚¨ãƒ©ãƒ¼"
            
            st.metric(
                "æ¨å®šã‚³ã‚¹ãƒˆ",
                f"Â¥{data['total_estimated_cost']:,}",
                budget_percentage
            )
        
        with col4:
            st.metric(
                "ç›®æ¨™é”æˆç¢ºç‡",
                f"{data['performance_predictions']['goal_achievement_probability']*100:.1f}%"
            )
        
        # æ–½ç­–ä¸€è¦§
        st.markdown('<h2 class="sub-header">ğŸ¯ æ¨å¥¨æ–½ç­–</h2>', unsafe_allow_html=True)
        
        for i, campaign in enumerate(data['recommended_campaigns']):
            card_class = "free-campaign" if not campaign['is_paid'] else "paid-campaign"
            
            with st.container():
                st.markdown(f'<div class="campaign-card {card_class}">', unsafe_allow_html=True)
                
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    st.markdown(f"### {campaign['campaign_name']}")
                    st.markdown(f"**ãƒãƒ£ãƒãƒ«:** {campaign['channel']}")
                    st.markdown(f"**èª¬æ˜:** {campaign['description']}")
                    st.markdown(f"**å®Ÿæ–½ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³:** {campaign['implementation_timeline']}")
                    
                    # å¿…è¦ãƒªã‚½ãƒ¼ã‚¹
                    resources_text = " | ".join(campaign['required_resources'])
                    st.markdown(f"**å¿…è¦ãƒªã‚½ãƒ¼ã‚¹:** {resources_text}")
                
                with col2:
                    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
                    st.markdown("**äºˆæ¸¬ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**")
                    st.markdown(f"ã‚³ã‚¹ãƒˆ: Â¥{campaign['estimated_cost']:,}")
                    st.markdown(f"ãƒªãƒ¼ãƒ: {campaign['estimated_reach']:,}äºº")
                    st.markdown(f"ç”³è¾¼: {campaign['estimated_conversions']}äºº")
                    st.markdown(f"CTR: {campaign['estimated_ctr']:.1f}%")
                    st.markdown(f"CVR: {campaign['estimated_cvr']:.1f}%")
                    if campaign['estimated_cpa'] > 0:
                        st.markdown(f"CPA: Â¥{campaign['estimated_cpa']:,}")
                    else:
                        st.markdown("CPA: ç„¡æ–™")
                    
                    # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢
                    confidence_color = "green" if campaign['confidence_score'] > 0.7 else "orange" if campaign['confidence_score'] > 0.5 else "red"
                    st.markdown(f"**ä¿¡é ¼åº¦:** <span style='color:{confidence_color}'>{campaign['confidence_score']*100:.0f}%</span>", unsafe_allow_html=True)
                
                st.markdown('</div>', unsafe_allow_html=True)
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
        show_performance_analysis(data)
        
        # ãƒªã‚¹ã‚¯ã¨ææ¡ˆ
        show_risks_and_suggestions(data)
        
    except Exception as e:
        st.error(f"âŒ æ–½ç­–ææ¡ˆè¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)}")
        st.error("ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")

def show_performance_analysis(data):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã®è¡¨ç¤º"""
    st.markdown('<h2 class="sub-header">ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ</h2>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        # æ–½ç­–åˆ¥ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°
        campaigns_df = pd.DataFrame(data['recommended_campaigns'])
        fig_conv = px.bar(
            campaigns_df,
            x='campaign_name',
            y='estimated_conversions',
            color='is_paid',
            title='æ–½ç­–åˆ¥äºˆæ¸¬ç”³è¾¼æ•°',
            color_discrete_map={True: '#ffc107', False: '#28a745'}
        )
        fig_conv.update_layout(xaxis_tickangle=-45)
        st.plotly_chart(fig_conv, use_container_width=True)
    
    with col2:
        # äºˆç®—é…åˆ†
        budget_data = []
        for campaign in data['recommended_campaigns']:
            budget_data.append({
                'campaign': campaign['campaign_name'],
                'cost': campaign['estimated_cost'],
                'type': 'æœ‰æ–™' if campaign['is_paid'] else 'ç„¡æ–™'
            })
        
        budget_df = pd.DataFrame(budget_data)
        fig_budget = px.pie(
            budget_df[budget_df['cost'] > 0],
            values='cost',
            names='campaign',
            title='äºˆç®—é…åˆ†'
        )
        st.plotly_chart(fig_budget, use_container_width=True)

def show_risks_and_suggestions(data):
    """ãƒªã‚¹ã‚¯ã¨ææ¡ˆã®è¡¨ç¤º"""
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown('<h3 class="sub-header">âš ï¸ ãƒªã‚¹ã‚¯è¦å› </h3>', unsafe_allow_html=True)
        
        if data['performance_predictions']['risk_factors']:
            for risk in data['performance_predictions']['risk_factors']:
                st.warning(f"âš ï¸ {risk}")
        else:
            st.success("âœ… ç‰¹ã«å¤§ããªãƒªã‚¹ã‚¯è¦å› ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
    
    with col2:
        st.markdown('<h3 class="sub-header">ğŸ’¡ æœ€é©åŒ–ææ¡ˆ</h3>', unsafe_allow_html=True)
        
        for suggestion in data['performance_predictions']['optimization_suggestions']:
            st.info(f"ğŸ’¡ {suggestion}")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    st.markdown('<h2 class="sub-header">ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ</h2>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        # CSV ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        campaigns_df = pd.DataFrame(data['recommended_campaigns'])
        csv = campaigns_df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ğŸ“Š æ–½ç­–ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv,
            file_name=f"event_campaigns_{datetime.now().strftime('%Y%m%d')}.csv",
            mime="text/csv"
        )
    
    with col2:
        # JSON ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        json_data = json.dumps(data, ensure_ascii=False, indent=2)
        st.download_button(
            label="ğŸ“‹ å…¨ãƒ‡ãƒ¼ã‚¿ã‚’JSONã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=json_data,
            file_name=f"event_analysis_{datetime.now().strftime('%Y%m%d')}.json",
            mime="application/json"
        )

def process_text_knowledge(content, data_system):
    """ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰çŸ¥è¦‹ã‚’æŠ½å‡º"""
    try:
        # Claude APIã‚’ä½¿ç”¨ã—ãŸåˆ†æ
        if hasattr(data_system, 'claude_client') and data_system.claude_client:
            result = data_system._analyze_document_with_claude(content, "ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«", "Text")
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç°¡æ˜“çš„ãªçŸ¥è¦‹æŠ½å‡º
            result = data_system._analyze_text_fallback(content, "ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«", "Text")
        
        return result
        
    except Exception as e:
        return {"success": False, "error": str(e)}

def process_paid_media_csv_import(uploaded_file, data_system):
    """æœ‰å„Ÿãƒ¡ãƒ‡ã‚£ã‚¢CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆå‡¦ç†"""
    with st.spinner("ğŸ’° æœ‰å„Ÿãƒ¡ãƒ‡ã‚£ã‚¢CSVãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­..."):
        try:
            import tempfile
            import os
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_file_path = tmp_file.name
            
            # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ
            result = data_system.import_existing_csv(tmp_file_path, "paid_media")
            
            # çµæœè¡¨ç¤º
            if result["success"]:
                st.success(f"âœ… {result['imported']}ä»¶ã®æœ‰å„Ÿãƒ¡ãƒ‡ã‚£ã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸï¼")
            else:
                st.error(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {result['error']}")
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            os.unlink(tmp_file_path)
            
        except Exception as e:
            st.error(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")

def process_web_ad_csv_import(uploaded_file, data_system):
    """WEBåºƒå‘ŠCSVã‚¤ãƒ³ãƒãƒ¼ãƒˆå‡¦ç†"""
    with st.spinner("ğŸŒ WEBåºƒå‘ŠCSVãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­..."):
        try:
            import tempfile
            import os
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_file_path = tmp_file.name
            
            # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ
            result = data_system.import_existing_csv(tmp_file_path, "web_advertising")
            
            # çµæœè¡¨ç¤º
            if result["success"]:
                st.success(f"âœ… {result['imported']}ä»¶ã®WEBåºƒå‘Šãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸï¼")
            else:
                st.error(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {result['error']}")
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            os.unlink(tmp_file_path)
            
        except Exception as e:
            st.error(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")

def process_free_campaign_csv_import(uploaded_file, data_system):
    """ç„¡å„Ÿæ–½ç­–CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆå‡¦ç†"""
    with st.spinner("ğŸ†“ ç„¡å„Ÿæ–½ç­–CSVãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­..."):
        try:
            import tempfile
            import os
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_file_path = tmp_file.name
            
            # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ
            result = data_system.import_existing_csv(tmp_file_path, "free_campaigns")
            
            # çµæœè¡¨ç¤º
            if result["success"]:
                st.success(f"âœ… {result['imported']}ä»¶ã®ç„¡å„Ÿæ–½ç­–ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸï¼")
            else:
                st.error(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {result['error']}")
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            os.unlink(tmp_file_path)
            
        except Exception as e:
            st.error(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")

def process_conference_import(csv_file_path, event_info, data_system):
    """ã‚«ãƒ³ãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹å®Ÿç¸¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆå‡¦ç†ï¼ˆæ‰‹å…¥åŠ›ï¼‹CSVï¼‰"""
    try:
        import pandas as pd
        
        # CSVèª­ã¿è¾¼ã¿
        try:
            df = pd.read_csv(csv_file_path, encoding='utf-8-sig')
        except UnicodeDecodeError:
            df = pd.read_csv(csv_file_path, encoding='shift-jis')
        
        errors = []
        applicant_count = 0
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
        import sqlite3
        conn = sqlite3.connect(data_system.db_path)
        cursor = conn.cursor()
        
        # participantsãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS participants (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                event_id INTEGER,
                job_title TEXT,
                position TEXT,
                company TEXT,
                industry TEXT,
                company_size TEXT,
                source_type TEXT,
                source_name TEXT,
                apply_date TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # ã‚¤ãƒ™ãƒ³ãƒˆåŸºæœ¬æƒ…å ±ã‚’ä¿å­˜
        try:
            actual_attendees = len(df)  # å®Ÿéš›ç”³è¾¼æ•°ã¯CSVã®è¡Œæ•°
            target_attendees = event_info["target_attendees"]
            budget = event_info["budget"]
            actual_cost = 0  # å®Ÿéš›ã‚³ã‚¹ãƒˆã¯æœªå…¥åŠ›
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆç®—
            conversion_rate = (actual_attendees / target_attendees * 100) if target_attendees > 0 else 0
            cpa = (actual_cost / actual_attendees) if actual_attendees > 0 else 0
            cost_efficiency = budget / actual_cost if actual_cost > 0 else 1
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’JSONå½¢å¼ã§ä½œæˆ
            import json
            performance_metrics = json.dumps({
                "conversion_rate": conversion_rate,
                "cpa": cpa,
                "cost_efficiency": cost_efficiency
            })
            
            # ä½¿ç”¨æ–½ç­–ã‚’JSONå½¢å¼ã§ä½œæˆ
            campaigns_used = json.dumps(["conference"])
            
            cursor.execute("""
                INSERT INTO historical_events 
                (event_name, category, theme, target_attendees, actual_attendees, budget, actual_cost, event_date, campaigns_used, performance_metrics)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                event_info["event_name"],
                event_info["category"],
                event_info["theme"],
                target_attendees,
                actual_attendees,
                budget,
                actual_cost,
                event_info["event_date"],
                campaigns_used,
                performance_metrics
            ))
            event_id = cursor.lastrowid
        except Exception as e:
            errors.append(f"ã‚¤ãƒ™ãƒ³ãƒˆåŸºæœ¬æƒ…å ±ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {"success": False, "error": f"ã‚¤ãƒ™ãƒ³ãƒˆåŸºæœ¬æƒ…å ±ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}"}
        
        # ç”³è¾¼è€…ãƒ‡ãƒ¼ã‚¿å‡¦ç†
        for index, row in df.iterrows():
            try:
                # åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆæ—¥æœ¬èªãƒ»è‹±èªå¯¾å¿œï¼‰
                job_title = get_column_value(row, ['è·ç¨®', 'Job Title', 'job_title'])
                position = get_column_value(row, ['å½¹è·', 'Position', 'position'])
                company = get_column_value(row, ['ä¼æ¥­å', 'Company', 'company'])
                industry = get_column_value(row, ['æ¥­ç¨®', 'Industry', 'industry'])
                company_size = get_column_value(row, ['å¾“æ¥­å“¡è¦æ¨¡', 'Company Size', 'company_size'])
                
                # å¿…é ˆé …ç›®ãƒã‚§ãƒƒã‚¯
                if not job_title or not position or not company or not industry or not company_size:
                    errors.append(f"è¡Œ{index+1}: å¿…é ˆé …ç›®ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                    continue
                
                # ç”³è¾¼è€…æƒ…å ±ã‚’participantsãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜ï¼ˆä»®ã®ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ï¼‰
                cursor.execute("""
                    INSERT OR IGNORE INTO participants 
                    (event_id, job_title, position, company, industry, company_size, source_type, source_name)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    event_id,
                    job_title,
                    position,
                    company,
                    industry,
                    company_size,
                    "conference",
                    event_info["event_name"]
                ))
                
                applicant_count += 1
                
            except Exception as e:
                errors.append(f"è¡Œ{index+1}: {str(e)}")
        
        conn.commit()
        conn.close()
        
        return {
            "success": True,
            "applicant_count": applicant_count,
            "errors": errors if errors else None
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

def process_paid_media_import(csv_file_path, media_info, data_system):
    """æœ‰å„Ÿãƒ¡ãƒ‡ã‚£ã‚¢å®Ÿç¸¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆå‡¦ç†ï¼ˆæ‰‹å…¥åŠ›ï¼‹CSVï¼‰"""
    try:
        import pandas as pd
        
        # CSVèª­ã¿è¾¼ã¿
        try:
            df = pd.read_csv(csv_file_path, encoding='utf-8-sig')
        except UnicodeDecodeError:
            df = pd.read_csv(csv_file_path, encoding='shift-jis')
        
        errors = []
        applicant_count = 0
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
        import sqlite3
        conn = sqlite3.connect(data_system.db_path)
        cursor = conn.cursor()
        
        # participantsãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS participants (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                event_id INTEGER,
                job_title TEXT,
                position TEXT,
                company TEXT,
                industry TEXT,
                company_size TEXT,
                source_type TEXT,
                source_name TEXT,
                apply_date TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # media_basic_infoãƒ†ãƒ¼ãƒ–ãƒ«ã«å¿…è¦ãªåˆ—ã‚’è¿½åŠ ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
        try:
            cursor.execute("ALTER TABLE media_basic_info ADD COLUMN cost INTEGER DEFAULT 0")
        except sqlite3.OperationalError:
            pass  # åˆ—ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆ
        
        try:
            cursor.execute("ALTER TABLE media_basic_info ADD COLUMN event_name TEXT")
        except sqlite3.OperationalError:
            pass
        
        try:
            cursor.execute("ALTER TABLE media_basic_info ADD COLUMN event_theme TEXT")
        except sqlite3.OperationalError:
            pass
        
        try:
            cursor.execute("ALTER TABLE media_basic_info ADD COLUMN event_category TEXT")
        except sqlite3.OperationalError:
            pass
        
        # æœ‰å„Ÿãƒ¡ãƒ‡ã‚£ã‚¢æƒ…å ±ã‚’ä¿å­˜
        try:
            cursor.execute("""
                INSERT INTO media_basic_info 
                (media_name, media_type, target_audience, cost, description, event_name, event_theme, event_category)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                media_info["media_name"],
                "paid_media",
                media_info["event_target"],
                media_info["media_cost"],
                f"æœ‰å„Ÿãƒ¡ãƒ‡ã‚£ã‚¢çµŒç”±: {media_info['event_name']}",
                media_info["event_name"],
                media_info["event_theme"],
                media_info["event_category"]
            ))
            media_id = cursor.lastrowid
        except Exception as e:
            errors.append(f"ãƒ¡ãƒ‡ã‚£ã‚¢åŸºæœ¬æƒ…å ±ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {"success": False, "error": f"ãƒ¡ãƒ‡ã‚£ã‚¢åŸºæœ¬æƒ…å ±ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}"}
        
        # ç”³è¾¼è€…ãƒ‡ãƒ¼ã‚¿å‡¦ç†
        for index, row in df.iterrows():
            try:
                # åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆæ—¥æœ¬èªãƒ»è‹±èªå¯¾å¿œï¼‰
                job_title = get_column_value(row, ['è·ç¨®', 'Job Title', 'job_title'])
                position = get_column_value(row, ['å½¹è·', 'Position', 'position'])
                company = get_column_value(row, ['ä¼æ¥­å', 'Company', 'company'])
                industry = get_column_value(row, ['æ¥­ç¨®', 'Industry', 'industry'])
                company_size = get_column_value(row, ['å¾“æ¥­å“¡è¦æ¨¡', 'Company Size', 'company_size'])
                source = get_column_value(row, ['ç”³è¾¼çµŒè·¯', 'Source', 'source'], default=media_info["media_name"])
                apply_date = get_column_value(row, ['ç”³è¾¼æ—¥', 'Apply Date', 'apply_date'], default=media_info["media_date"])
                
                # å¿…é ˆé …ç›®ãƒã‚§ãƒƒã‚¯
                if not job_title or not position or not company or not industry or not company_size:
                    errors.append(f"è¡Œ{index+1}: å¿…é ˆé …ç›®ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                    continue
                
                # ç”³è¾¼è€…æƒ…å ±ã‚’participantsãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
                cursor.execute("""
                    INSERT OR IGNORE INTO participants 
                    (event_id, job_title, position, company, industry, company_size, source_type, source_name, apply_date)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    media_id,  # ãƒ¡ãƒ‡ã‚£ã‚¢IDã‚’ä»®ã«event_idã¨ã—ã¦ä½¿ç”¨
                    job_title,
                    position,
                    company,
                    industry,
                    company_size,
                    "paid_media",
                    source,
                    apply_date
                ))
                
                applicant_count += 1
                
            except Exception as e:
                errors.append(f"è¡Œ{index+1}: {str(e)}")
        
        conn.commit()
        conn.close()
        
        return {
            "success": True,
            "applicant_count": applicant_count,
            "errors": errors if errors else None
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

def get_column_value(row, column_names, default=None):
    """è¤‡æ•°ã®åˆ—åå€™è£œã‹ã‚‰å€¤ã‚’å–å¾—"""
    import pandas as pd
    for col_name in column_names:
        if col_name in row and pd.notna(row[col_name]):
            return str(row[col_name]).strip()
    return default

if __name__ == "__main__":
    main() 