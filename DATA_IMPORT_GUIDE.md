# 📥 データインポート完全ガイド

## ✨ **LLM技術 × 構造化データの最適な組み合わせ**

このガイドでは、**LLM技術による柔軟な解析**と**構造化データによる精度向上**を両立させる方法を説明します。

---

## 🎯 **推奨アプローチ**

### **1. 構造化テンプレート優先**
- まずは推奨テンプレートでの入力を検討
- データの一貫性と分析精度が向上
- 自動処理の成功率が大幅に向上

### **2. 柔軟なLLM解析をサポート**
- 既存の不完全なデータも活用可能
- 多様なフォーマットに対応
- 徐々にデータ品質を向上

---

## 📊 **データ種別別ガイド**

### **🎪 A. イベント実績データ**

#### **推奨インポート方法**
1. **CSVテンプレート使用（最優先）**
   - ファイル: `templates/event_data_template.csv`
   - 自動マッピング率: 95%以上
   - 処理速度: 最高速

2. **PDFレポート**
   - 推奨構造: `templates/pdf_format_guide.md`参照
   - LLM解析で柔軟に対応
   - 自動マッピング率: 80-90%

3. **既存Excel/CSV**
   - 列名の自動推定
   - 欠損データの補完提案
   - 自動マッピング率: 70-85%

#### **必須データ項目**
| 項目 | 重要度 | 例 | 備考 |
|------|--------|-----|------|
| **イベント名** | 🔴必須 | AI Engineering Summit | 一意識別のため |
| **開催日** | 🔴必須 | 2024-06-15 | YYYY-MM-DD形式 |
| **目標申込数** | 🔴必須 | 500 | 数値のみ |
| **実際申込数** | 🔴必須 | 450 | 数値のみ |
| **予算** | 🟡推奨 | 1000000 | 円単位 |
| **カテゴリ** | 🟡推奨 | 技術カンファレンス | 分類用 |
| **ターゲット業種** | 🟡推奨 | IT・情報通信 | 複数可 |

---

### **📰 B. メディア属性データ**

#### **推奨インポート方法**
1. **CSVテンプレート**
   - ファイル: `templates/media_data_template.csv`
   - メディア特性を正確に記録

2. **媒体資料PDF**
   - 媒体概要、読者属性、広告実績を抽出
   - LLM技術で自動データ化

#### **必須データ項目**
| 項目 | 重要度 | 例 | 備考 |
|------|--------|-----|------|
| **メディア名** | 🔴必須 | TechCrunch Japan | 正式名称 |
| **主要読者層** | 🔴必須 | IT・エンジニア | 業種・職種 |
| **リーチ数** | 🟡推奨 | 50000 | 月間ユニーク数 |
| **CTR平均** | 🟡推奨 | 2.5 | パーセント |
| **CPA平均** | 🟡推奨 | 8000 | 円単位 |

---

### **🧠 C. 知見・ノウハウデータ**

#### **推奨インポート方法**
1. **CSVテンプレート**
   - ファイル: `templates/insights_template.csv`
   - 構造化された知見管理

2. **自由形式テキスト/PDF**
   - 振り返りレポート、議事録などから抽出
   - LLM技術で知見を構造化

#### **必須データ項目**
| 項目 | 重要度 | 例 | 備考 |
|------|--------|-----|------|
| **知見内容** | 🔴必須 | 土曜開催で参加率15%向上 | 具体的で定量的 |
| **カテゴリ** | 🔴必須 | 集客施策 | 分類用 |
| **影響度** | 🟡推奨 | 高 | 高/中/低 |
| **信頼度** | 🟡推奨 | 高 | 高/中/低 |

---

## 🚀 **実践的インポート手順**

### **Step 1: データの準備**
```
1. 既存データの整理
   - Excel/CSV → テンプレート形式に変換
   - PDF → 可能な限りテキスト情報を含む形式

2. データ品質チェック
   - 必須項目の確認
   - 数値データの単位統一
   - 日付形式の統一（YYYY-MM-DD）
```

### **Step 2: インポート実行**
```
1. アプリ「📊 データ管理」タブにアクセス
2. 「📥データインポート」を選択
3. ファイルをアップロード
4. 自動マッピング結果を確認
5. 必要に応じて手動調整
6. インポート実行
```

### **Step 3: 品質向上**
```
1. 「📊データ分析」で結果確認
2. 重複・矛盾データの修正
3. 欠損項目の補完
4. 継続的な改善
```

---

## 🎨 **データ品質向上のコツ**

### **✅ Good Practice**

#### **CSV作成時**
- **列名は日本語OK**: 「イベント名」「申込数」など
- **数値は半角**: 1000000（カンマなし）
- **日付統一**: 2024-01-15形式
- **リスト項目**: 「IT・製造業・金融業」（・区切り）

#### **PDF作成時**
- **表形式多用**: 数値データは表で整理
- **見出し明確化**: ■●で構造化
- **具体的数値**: 「30%向上」「15人増加」
- **単位明記**: 「500人」「100万円」

### **❌ 避けるべき事項**

#### **CSV/Excel**
- 結合セル・複雑な装飾
- 全角数値・カンマ入り数値
- 曖昧な列名（「その他」「備考」のみ）
- 空行・空列の多用

#### **PDF**
- 画像のみのグラフ・表
- 極小フォント
- 複雑すぎるレイアウト
- 「多い」「少ない」などの曖昧表現

---

## 🔧 **トラブルシューティング**

### **問題1: インポートエラー**
```
原因: データ形式が認識できない
対策: 
- テンプレートと比較
- 文字エンコード確認（UTF-8推奨）
- ファイル破損チェック
```

### **問題2: マッピング精度が低い**
```
原因: 列名・項目名が不明確
対策:
- 列名を推奨形式に変更
- 手動マッピングで補正
- データ辞書の活用
```

### **問題3: 重複データ**
```
原因: 同じイベント・メディアが複数存在
対策:
- 🧹 データクリーニング機能を使用
- 一意キー（イベント名+日付）での確認
```

---

## 📈 **データ活用の最大化**

### **段階的改善アプローチ**

#### **Phase 1: 基本データ整備（1-2週間）**
- 過去6ヶ月のイベントデータをCSV化
- 主要メディアのリストアップ
- 基本的な知見を文書化

#### **Phase 2: データ品質向上（1ヶ月）**
- 詳細な参加者属性データ追加
- メディア別パフォーマンスデータ蓄積
- 施策別効果測定の精緻化

#### **Phase 3: 高度活用（継続的）**
- AIエンジンによる予測精度向上
- リアルタイムデータ更新
- 新しい知見の継続的蓄積

---

## 🎯 **成功指標**

### **データ品質KPI**
- **完全性**: 必須項目充足率 90%以上
- **精度**: 自動マッピング成功率 85%以上  
- **一貫性**: 重複・矛盾データ率 5%以下
- **鮮度**: 月次データ更新率 100%

### **活用効果KPI**
- **予測精度**: 申込数予測誤差 15%以内
- **提案適合性**: 推奨施策採用率 70%以上
- **効率向上**: 施策検討時間 50%短縮
- **ROI改善**: イベント収益率 20%向上

---

## 💡 **最後に**

### **推奨ワークフロー**
1. **既存データ**: まずはそのままインポート
2. **テンプレート移行**: 徐々に推奨形式に統一
3. **品質向上**: 継続的なデータクリーニング
4. **高度活用**: AIエンジンとの組み合わせ

**完璧を求めず、継続的な改善が成功の鍵です！** 🚀

データに関するご質問があれば、いつでもお気軽にお声かけください。 